{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "import signal\n",
    "from collections import OrderedDict\n",
    "from dataclasses import dataclass\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "import numpy as np\n",
    "import subprocess\n",
    "from operator import itemgetter, attrgetter\n",
    "import re\n",
    "import subprocess\n",
    "import cv2\n",
    "import traceback\n",
    "import math\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import glob\n",
    "import itertools\n",
    "from scipy.spatial import distance\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class vector3:\n",
    "    x: float = 0.0\n",
    "    y: float = 0.0\n",
    "    z: float = 0.0\n",
    "\n",
    "    def __array__(self) -> np.ndarray:\n",
    "        return np.array([self.x, self.y, self.z])\n",
    "\n",
    "    def clamp(self, mmin, mmax):\n",
    "        self.x = max(mmin, self.x)\n",
    "        self.x = min(mmax, self.x)\n",
    "        self.y = max(mmin, self.y)\n",
    "        self.y = min(mmax, self.y)\n",
    "        self.z = max(mmin, self.z)\n",
    "        self.z = min(mmax, self.z)\n",
    "\n",
    "    def mult_me(self, d):\n",
    "        self.x *= d\n",
    "        self.y *= d\n",
    "        self.z *= d\n",
    "\n",
    "    def normalize_me(self):\n",
    "        if self.x == 0 and self.y == 0 and self.z == 0:\n",
    "            return\n",
    "        len = self.get_length()\n",
    "        # print('1: ', self.x, ' ', self.y, ' ', self.z, ' ', len)\n",
    "        self.x /= len\n",
    "        self.y /= len\n",
    "        self.z /= len\n",
    "        # print('2: ', self.x, ' ', self.y, ' ', self.z, ' ', len)\n",
    "        return vector3(self.x, self.y, self.z)\n",
    "\n",
    "    def get_length(self):\n",
    "        return np.sqrt(np.sum(np.power(np.array(self), 2)))\n",
    "\n",
    "    def copy(self):\n",
    "        return vector3(self.x, self.y, self.z)\n",
    "\n",
    "    def round(self, d):\n",
    "        self.x = round(self.x, d)\n",
    "        self.y = round(self.y, d)\n",
    "        self.z = round(self.z, d)\n",
    "\n",
    "    def round_(self, d):\n",
    "        return vector3(round(self.x, d), round(self.y, d), round(self.z, d))\n",
    "\n",
    "    def get_rotated(self, tq):\n",
    "        q = quat(self.x * tq.w + self.z * tq.y - self.y * tq.z,\n",
    "                 self.y * tq.w + self.x * tq.z - self.z * tq.x,\n",
    "                 self.z * tq.w + self.y * tq.x - self.x * tq.y,\n",
    "                 self.x * tq.x + self.y * tq.y + self.z * tq.z)\n",
    "        return vector3(tq.w * q.x + tq.x * q.w + tq.y * q.z - tq.z * q.y,\n",
    "                       tq.w * q.y + tq.y * q.w + tq.z * q.x - tq.x * q.z,\n",
    "                       tq.w * q.z + tq.z * q.w + tq.x * q.y - tq.y * q.x)\n",
    "\n",
    "    def add_vector3(self, t):\n",
    "        return vector3(round(self.x + t.x, 8), round(self.y + t.y, 8), round(self.z + t.z, 8))\n",
    "\n",
    "    def sub_vector3(self, t):\n",
    "        return vector3(round(self.x - t.x, 8), round(self.y - t.y, 8), round(self.z - t.z, 8))\n",
    "\n",
    "    def get_dot(self, t):\n",
    "        return self.x * t.x + self.y * t.y + self.z * t.z\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class quat:\n",
    "    x: float = 0.0\n",
    "    y: float = 0.0\n",
    "    z: float = 0.0\n",
    "    w: float = 1.0\n",
    "\n",
    "    def __array__(self) -> np.ndarray:\n",
    "        return np.array([self.x, self.y, self.z, self.w])\n",
    "\n",
    "    def mult_me_quat(self, q):\n",
    "        tmp = self.copy()\n",
    "        self.x = tmp.w * q.x + tmp.x * q.w + tmp.y * q.z - tmp.z * q.y\n",
    "        self.y = tmp.w * q.y - tmp.x * q.z + tmp.y * q.w + tmp.z * q.x\n",
    "        self.z = tmp.w * q.z + tmp.x * q.y - tmp.y * q.x + tmp.z * q.w\n",
    "        self.w = tmp.w * q.w - tmp.x * q.x - tmp.y * q.y - tmp.z * q.z\n",
    "\n",
    "    def mult_quat(self, q):\n",
    "        tmp = self.copy()\n",
    "        return quat(tmp.w * q.x + tmp.x * q.w + tmp.y * q.z - tmp.z * q.y,\n",
    "                    tmp.w * q.y - tmp.x * q.z + tmp.y * q.w + tmp.z * q.x,\n",
    "                    tmp.w * q.z + tmp.x * q.y - tmp.y * q.x + tmp.z * q.w,\n",
    "                    tmp.w * q.w - tmp.x * q.x - tmp.y * q.y - tmp.z * q.z)\n",
    "\n",
    "    def copy(self):\n",
    "        return quat(self.x, self.y, self.z, self.w)\n",
    "\n",
    "    '''\n",
    "    def inverse(self):\n",
    "        dot = quat_get_dot(self, self)\n",
    "        self.x = -self.x\n",
    "        self.y = -self.y\n",
    "        self.z = -self.z\n",
    "        self.mult_me(1 / dot)\n",
    "    '''\n",
    "\n",
    "    def round(self, d):\n",
    "        self.x = round(self.x, d)\n",
    "        self.y = round(self.y, d)\n",
    "        self.z = round(self.z, d)\n",
    "        self.w = round(self.w, d)\n",
    "\n",
    "    def round_(self, d):\n",
    "        return quat(round(self.x, d), round(self.y, d), round(self.z, d), round(self.w, d))\n",
    "\n",
    "    def inverse(self):\n",
    "        dot = quat_get_dot(self, self)\n",
    "        self.x = -self.x\n",
    "        self.y = -self.y\n",
    "        self.z = -self.z\n",
    "        self.x = self.x / dot\n",
    "        self.y = self.y / dot\n",
    "        self.z = self.z / dot\n",
    "        self.w = self.w / dot\n",
    "\n",
    "\n",
    "def quat_get_dot(self, t):\n",
    "    return self.x * t.x + self.y * t.y + self.z * t.z + self.w * t.w\n",
    "\n",
    "\n",
    "def get_dot_point(pt, t):\n",
    "    return pt.get_dot(t)\n",
    "\n",
    "\n",
    "def nomalize_point(pt):\n",
    "    return pt.normalize_me()\n",
    "\n",
    "\n",
    "def rotate_point(pt, pose):\n",
    "    return pt.get_rotated(pose['orient'])\n",
    "\n",
    "\n",
    "def transfer_point(pt, pose):\n",
    "    r_pt = pt.get_rotated(pose['orient'])\n",
    "    return r_pt.add_vector3(pose['position'])\n",
    "\n",
    "\n",
    "def move_point(pt, pose):\n",
    "    return pt.add_vector3(pose)\n",
    "\n",
    "\n",
    "def transfer_point_inverse(pt, pose):\n",
    "    t = copy.deepcopy(pose)\n",
    "    t['orient'].inverse()\n",
    "    r_pt = pt.sub_vector3(t['position'])\n",
    "    return r_pt.get_rotated(t['orient'])\n",
    "\n",
    "\n",
    "def get_quat_from_euler(order, value):\n",
    "    rt = R.from_euler(order, value, degrees=True)\n",
    "    return quat(rt.as_quat()[0], rt.as_quat()[1], rt.as_quat()[2], rt.as_quat()[3])\n",
    "\n",
    "\n",
    "def pose_apply(a, b):\n",
    "    return {'position': transfer_point(a['position'], b), 'orient': b['orient'].mult_quat(a['orient'])}\n",
    "\n",
    "\n",
    "def pose_apply_inverse(a, b):\n",
    "    t = copy.deepcopy(b)\n",
    "    t['orient'].inverse()\n",
    "    tmp = a['position'].sub_vector3(t['position'])\n",
    "    return {'position': tmp.get_rotated(t['orient']), 'orient': t['orient'].mult_quat(a['orient'])}\n",
    "\n",
    "\n",
    "def get_euler_from_quat(order, q):\n",
    "    rt = R.from_quat(np.array(q))\n",
    "    return rt.as_euler(order, degrees=True)\n",
    "\n",
    "\n",
    "def unit_vector(vector):\n",
    "    \"\"\"Returnstheunitvectorofthevector.\"\"\"\n",
    "    return vector / np.linalg.norm(vector)\n",
    "\n",
    "\n",
    "def angle_between(v1, v2):\n",
    "    \"\"\"Returnstheangleinradiansbetweenvectors'v1'and'v2'::\n",
    "    >>>angle_between((1,0,0),(0,1,0))\n",
    "    1.5707963267948966\n",
    "    >>>angle_between((1,0,0),(1,0,0))\n",
    "    0.0\n",
    "    >>>angle_between((1,0,0),(-1,0,0))\n",
    "    3.141592653589793\n",
    "    \"\"\"\n",
    "    v1_u = unit_vector(v1)\n",
    "    v2_u = unit_vector(v2)\n",
    "    return np.arccos(np.clip(np.dot(v1_u, v2_u), -1.0, 1.0))\n",
    "\n",
    "\n",
    "def terminal_cmd(cmd_m, cmd_s):\n",
    "    print('start ', terminal_cmd.__name__)\n",
    "    try:\n",
    "        result = subprocess.run([cmd_m, cmd_s], stdout=subprocess.PIPE).stdout.decode('utf-8')\n",
    "\n",
    "        device_re = re.compile(b\"Bus\\s+(?P<bus>\\d+)\\s+Device\\s+(?P<device>\\d+).+ID\\s(?P<id>\\w+:\\w+)\\s(?P<tag>.+)$\",\n",
    "                               re.I)\n",
    "        df = subprocess.check_output(\"lsusb\")\n",
    "        devices = []\n",
    "        for i in df.split(b'\\n'):\n",
    "            if i:\n",
    "                info = device_re.match(i)\n",
    "                if info:\n",
    "                    dinfo = info.groupdict()\n",
    "                    dinfo['device'] = '/dev/bus/usb/%s/%s' % (dinfo.pop('bus'), dinfo.pop('device'))\n",
    "                    devices.append(dinfo)\n",
    "    except:\n",
    "        print('exception')\n",
    "        traceback.print_exc()\n",
    "    else:\n",
    "        print('done')\n",
    "    finally:\n",
    "        if DEBUG == ENABLE:\n",
    "            print(devices)\n",
    "    temp = result.split('\\n\\n')\n",
    "    Rift_Sensor = \"Rift Sensor\"\n",
    "    print(\"==================================================\")\n",
    "    ret_val = []\n",
    "    for i in range(len(temp)):\n",
    "        if Rift_Sensor in temp[i]:\n",
    "            ret_val.append(temp[i])\n",
    "            print(\"add list rift_sensor\", temp[i])\n",
    "        else:\n",
    "            print(\"skipping camera\", temp[i])\n",
    "    print(\"==================================================\")\n",
    "    return ret_val\n",
    "\n",
    "\n",
    "def init_model_json(cam_dev_list):\n",
    "    print('start ', init_model_json.__name__)\n",
    "    camera_info_array = []\n",
    "    try:\n",
    "        if DEBUG == ENABLE:\n",
    "            print(cam_dev_list, ' count:', len(cam_dev_list))\n",
    "        for i in range(len(cam_dev_list)):\n",
    "            print('\\n')\n",
    "            print('cam_id[', i, '] :', cam_json[i])\n",
    "            jsonObject = json.load(open(''.join(['jsons/', f'{cam_json[i]}'])))\n",
    "\n",
    "            cam_info = cam_dev_list[i].split('\\n\\t')\n",
    "\n",
    "            '''                        \n",
    "              k = [ k₁ k₂, k₃, k4 ] for CV1 fisheye distortion                    \n",
    "\n",
    "                  ⎡ fx 0  cx ⎤\n",
    "              A = ⎢ 0  fy cy ⎥\n",
    "                  ⎣ 0  0  1  ⎦          \n",
    "            '''\n",
    "            f = jsonObject.get('camera_f')\n",
    "            c = jsonObject.get('camera_c')\n",
    "            k = jsonObject.get('camera_k')\n",
    "\n",
    "            A = np.array([[f[0], 0.0, c[0]],\n",
    "                          [0.0, f[1], c[1]],\n",
    "                          [0.0, 0.0, 1.0]], dtype=np.float64)\n",
    "            K = np.array([[k[0]], [k[1]], [k[2]], [k[3]]], dtype=np.float64)\n",
    "\n",
    "            if DEBUG == ENABLE:\n",
    "                print('cameraK: ', A)\n",
    "                print('dist_coeff: ', K)\n",
    "                print('cam_info: ', cam_info)\n",
    "\n",
    "            camera_info_array.append({'idx': i,\n",
    "                                      'name': cam_info[0],\n",
    "                                      'port': cam_info[1],\n",
    "                                      'json': cam_json[i],\n",
    "                                      'cam_cal': {'cameraK': A, 'dist_coeff': K},\n",
    "\n",
    "                                      'blobs': [],\n",
    "                                      'med_blobs': [],\n",
    "\n",
    "                                      'distorted_2d': [],\n",
    "                                      'undistorted_2d': [],\n",
    "\n",
    "                                      'track_cal': {'data': [], 'recording': {'name': NOT_SET}},\n",
    "\n",
    "                                      'D_R_T': {'rvecs': NOT_SET, 'tvecs': NOT_SET},\n",
    "                                      'D_R_T_A': [],\n",
    "                                      'RER': {'C_R_T': {'rvecs': NOT_SET, 'tvecs': NOT_SET}}})\n",
    "\n",
    "    except:\n",
    "        print('exception')\n",
    "        traceback.print_exc()\n",
    "    finally:\n",
    "        print('done')\n",
    "    return camera_info_array\n",
    "\n",
    "\n",
    "def init_coord_json(file):\n",
    "    print('start ', init_coord_json.__name__)\n",
    "    try:\n",
    "        json_file = open(''.join(['jsons/specs/', f'{file}']))\n",
    "        jsonObject = json.load(json_file)\n",
    "        model_points = jsonObject.get('TrackedObject').get('ModelPoints')\n",
    "        pts = [0 for i in range(len(model_points))]\n",
    "        for data in model_points:\n",
    "            idx = data.split('Point')[1]\n",
    "            x = model_points.get(data)[0]\n",
    "            y = model_points.get(data)[1]\n",
    "            z = model_points.get(data)[2]\n",
    "            u = model_points.get(data)[3]\n",
    "            v = model_points.get(data)[4]\n",
    "            w = model_points.get(data)[5]\n",
    "            r1 = model_points.get(data)[6]\n",
    "            r2 = model_points.get(data)[7]\n",
    "            r3 = model_points.get(data)[8]\n",
    "            pts[int(idx)] = {'idx': idx,\n",
    "                             'pos': [x, y, z],\n",
    "                             'dir': [u, v, w],\n",
    "                             'res': [r1, r2, r3],\n",
    "                             'pair_xy': [],\n",
    "                             'remake_3d': []}\n",
    "\n",
    "            print(''.join(['{ .pos = {{', f'{x}', ',', f'{y}', ',', f'{z}',\n",
    "                           ' }}, .dir={{', f'{u}', ',', f'{v}', ',', f'{w}', ' }}, .pattern=', f'{idx}', '},']))\n",
    "    except:\n",
    "        print('exception')\n",
    "        traceback.print_exc()\n",
    "    finally:\n",
    "        print('done')\n",
    "    return pts\n",
    "\n",
    "\n",
    "def rw_json_data(rw_mode, path, data):\n",
    "    try:\n",
    "        if rw_mode == READ:\n",
    "            with open(path, 'r', encoding=\"utf-8\") as rdata:\n",
    "                json_data = json.load(rdata)\n",
    "            return json_data\n",
    "        elif rw_mode == WRITE:\n",
    "            with open(path, 'w', encoding=\"utf-8\") as wdata:\n",
    "                json.dump(data, wdata, ensure_ascii=False, indent=\"\\t\")\n",
    "        else:\n",
    "            print('not support mode')\n",
    "    except:\n",
    "        print('exception')\n",
    "        return ERROR\n",
    "\n",
    "\n",
    "def rw_file_storage(rw_cmd, left_map, right_map):\n",
    "    if rw_cmd == WRITE:\n",
    "        print(\"WRITE parameters ......\")\n",
    "        cv_file = cv2.FileStorage(\"improved_params2.xml\", cv2.FILE_STORAGE_WRITE)\n",
    "        cv_file.write(\"Left_Stereo_Map_x\", left_map[0])\n",
    "        cv_file.write(\"Left_Stereo_Map_y\", left_map[1])\n",
    "        cv_file.write(\"Right_Stereo_Map_x\", right_map[0])\n",
    "        cv_file.write(\"Right_Stereo_Map_y\", right_map[1])\n",
    "        cv_file.release()\n",
    "    else:\n",
    "        print(\"READ parameters ......\")\n",
    "        try:\n",
    "            # FILE_STORAGE_READ\n",
    "            cv_file = cv2.FileStorage(\"improved_params2.xml\", cv2.FILE_STORAGE_READ)\n",
    "            # note we also have to specify the type to retrieve other wise we only get a\n",
    "            # FileNode object back instead of a matrix\n",
    "            left_map = (cv_file.getNode(\"Left_Stereo_Map_x\").mat(), cv_file.getNode(\"Left_Stereo_Map_y\").mat())\n",
    "            right_map = (cv_file.getNode(\"Right_Stereo_Map_x\").mat(), cv_file.getNode(\"Right_Stereo_Map_y\").mat())\n",
    "\n",
    "            cv_file.release()\n",
    "\n",
    "            return DONE, left_map, right_map\n",
    "        except:\n",
    "            traceback.print_exc()\n",
    "            return ERROR, NOT_SET, NOT_SET\n",
    "\n",
    "\n",
    "leds_dic = {}\n",
    "\n",
    "ENABLE = 1\n",
    "DISABLE = 0\n",
    "\n",
    "D3DT = 4\n",
    "D3D = 3\n",
    "D2D = 2\n",
    "\n",
    "READ = 0\n",
    "WRITE = 1\n",
    "\n",
    "ERROR = -1\n",
    "SUCCESS = 1\n",
    "\n",
    "DONE = 'DONE'\n",
    "NOT_SET = 'NOT_SET'\n",
    "\n",
    "SUDO_PASSWORD = ''\n",
    "\n",
    "# CAMERA\n",
    "cameraK = np.eye(3).astype(np.float64)\n",
    "distCoeff = np.zeros((4, 1)).astype(np.float64)\n",
    "\n",
    "DEBUG = ENABLE\n",
    "\n",
    "LOOP_CNT = 100\n",
    "\n",
    "CAP_PROP_FRAME_WIDTH = 1280\n",
    "CAP_PROP_FRAME_HEIGHT = 960\n",
    "\n",
    "MAX_BLOB_SIZE = 250\n",
    "\n",
    "CV_FINDCONTOUR_LVL = 140\n",
    "CV_THRESHOLD = 170\n",
    "CV_MIN_THRESHOLD = 170\n",
    "CV_MID_THRESHOLD = 190\n",
    "CV_MAX_THRESHOLD = 255\n",
    "\n",
    "DO_ESTIMATE_POSE = ENABLE\n",
    "DO_SOLVEPNP_REFINE = DISABLE\n",
    "DO_UNDISTORT = DISABLE\n",
    "DO_SOLVEPNP_RANSAC = ENABLE\n",
    "USE_PRINT_FRAME = DISABLE\n",
    "\n",
    "LED_COUNT = 15\n",
    "\n",
    "ORIGIN = 'rifts2_left.json'\n",
    "JSON_FILE = 'stereo_json'\n",
    "\n",
    "cam_json = ['WMTD307H601E9L.json', 'WMTD302J600GA9.json']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_solvePNP(cam_id, frame, blob_array):\n",
    "    model_points = []\n",
    "    image_points = []\n",
    "    led_ids = []\n",
    "    interationsCount = 100\n",
    "    confidence = 0.99\n",
    "\n",
    "    for blobs in blob_array:\n",
    "        led_num = int(blobs['idx'])\n",
    "        # if DEBUG == ENABLE:\n",
    "        #     print('idx:', led_num, ' added 3d', leds_dic['pts'][led_num]['pos'], ' remake: ',\n",
    "        #           leds_dic['target_pts'][led_num]['remake_3d'],\n",
    "        #           ' 2d', [blobs['cx'], blobs['cy']])\n",
    "\n",
    "        model_points.append(leds_dic['pts'][led_num]['pos'])\n",
    "        led_ids.append(led_num)\n",
    "        image_points.append([blobs['cx'], blobs['cy']])\n",
    "\n",
    "    model_points_len = len(model_points)\n",
    "    image_points_len = len(image_points)\n",
    "\n",
    "    # check assertion\n",
    "    if model_points_len != image_points_len:\n",
    "        print(\"assertion len is not equal\")\n",
    "        return ERROR\n",
    "\n",
    "    if model_points_len < 4 or image_points_len < 4:\n",
    "        print(\"assertion < 4: \")\n",
    "        return ERROR\n",
    "\n",
    "    camera_k = leds_dic['cam_info'][cam_id]['cam_cal']['cameraK']\n",
    "    dist_coeff = leds_dic['cam_info'][cam_id]['cam_cal']['dist_coeff']\n",
    "\n",
    "    list_2d_distorted = np.zeros((image_points_len, 1, 2), dtype=np.float64)\n",
    "    for i in range(image_points_len):\n",
    "        list_2d_distorted[i] = image_points[i]\n",
    "\n",
    "    points3D = np.array(model_points)\n",
    "\n",
    "    list_2d_undistorted = cv2.fisheye.undistortPoints(list_2d_distorted, camera_k, dist_coeff)\n",
    "    leds_dic['cam_info'][cam_id]['distorted_2d'] = copy.deepcopy(list_2d_distorted)\n",
    "    leds_dic['cam_info'][cam_id]['undistorted_2d'] = copy.deepcopy(list_2d_undistorted)\n",
    "\n",
    "    if DO_UNDISTORT == ENABLE:\n",
    "        temp_points2D = []\n",
    "        for u_data in list_2d_undistorted:\n",
    "            temp_points2D.append([u_data[0][0], u_data[0][1]])\n",
    "        points2D = np.array(temp_points2D)\n",
    "        temp_camera_k = cameraK\n",
    "        temp_dist_coeff = distCoeff\n",
    "    else:\n",
    "        points2D = np.array(image_points)\n",
    "        temp_camera_k = leds_dic['cam_info'][cam_id]['cam_cal']['cameraK']\n",
    "        temp_dist_coeff = leds_dic['cam_info'][cam_id]['cam_cal']['dist_coeff']\n",
    "\n",
    "    if DO_SOLVEPNP_RANSAC == ENABLE:\n",
    "        success, rvecs, tvecs, inliers = cv2.solvePnPRansac(points3D, points2D,\n",
    "                                                            temp_camera_k,\n",
    "                                                            temp_dist_coeff,\n",
    "                                                            useExtrinsicGuess=True,\n",
    "                                                            iterationsCount=interationsCount,\n",
    "                                                            confidence=confidence,\n",
    "                                                            reprojectionError=1.0,\n",
    "                                                            flags=cv2.SOLVEPNP_ITERATIVE)\n",
    "\n",
    "    else:\n",
    "        success, rvecs, tvecs = cv2.solvePnP(points3D, points2D,\n",
    "                                             temp_camera_k,\n",
    "                                             temp_dist_coeff,\n",
    "                                             flags=cv2.SOLVEPNP_AP3P)\n",
    "        # length = len(points2D)\n",
    "        # for i in range(length):\n",
    "        #     inliers = np.array(\n",
    "        #         [i for i in range(length)]).reshape(\n",
    "        #         length, 1)\n",
    "\n",
    "    # ret, RER, TRER, candidate_array, except_inlier = cal_RER_px(led_ids, frame,\n",
    "    #                                                             points3D, points2D,\n",
    "    #                                                             inliers,\n",
    "    #                                                             rvecs,\n",
    "    #                                                             tvecs,\n",
    "    #                                                             temp_camera_k,\n",
    "    #                                                             temp_dist_coeff, DONE)\n",
    "\n",
    "    # if ret == SUCCESS:\n",
    "    #     #####\n",
    "    #     leds_dic['cam_info'][cam_id]['D_R_T_A'].append({'rvecs': rvecs, 'tvecs': tvecs})\n",
    "    #     #####\n",
    "    #     leds_dic['cam_info'][cam_id]['RER']['C_R_T'] = {'rvecs': rvecs, 'tvecs': tvecs}\n",
    "    #     return SUCCESS, candidate_array\n",
    "    # else:\n",
    "    #     return ERROR, candidate_array\n",
    "\n",
    "    leds_dic['cam_info'][cam_id]['D_R_T_A'].append({'rvecs': rvecs, 'tvecs': tvecs})\n",
    "    #####\n",
    "    leds_dic['cam_info'][cam_id]['RER']['C_R_T'] = {'rvecs': rvecs, 'tvecs': tvecs}\n",
    "    return SUCCESS, blob_array\n",
    "\n",
    "\n",
    "def cal_RER_px(led_ids, frame, points3D, points2D, inliers, rvecs, tvecs, camera_k, dist_coeff, status):\n",
    "    # Compute re-projection error.\n",
    "    blob_array = []\n",
    "    points2D_reproj = cv2.projectPoints(points3D, rvecs,\n",
    "                                        tvecs, camera_k, dist_coeff)[0].squeeze(1)\n",
    "    # print('points2D_reproj\\n', points2D_reproj, '\\npoints2D\\n', points2D, '\\n inliers: ', inliers)\n",
    "    assert (points2D_reproj.shape == points2D.shape)\n",
    "    error = (points2D_reproj - points2D)[inliers]  # Compute error only over inliers.\n",
    "    # print('error', error)\n",
    "    rmse = 0.0\n",
    "    dis = 0.0\n",
    "    led_except = -1\n",
    "    except_inlier = -1\n",
    "    led_dis = []\n",
    "\n",
    "    for idx, error_data in enumerate(error[:, 0]):\n",
    "        rmse += np.power(error_data[0], 2) + np.power(error_data[1], 2)\n",
    "        temp_dis = np.power(error_data[0], 2) + np.power(error_data[1], 2)\n",
    "        led_dis.append(temp_dis)\n",
    "\n",
    "        if status == NOT_SET:\n",
    "            if temp_dis > dis:\n",
    "                dis = temp_dis\n",
    "                led_except = led_ids[idx]\n",
    "                except_inlier = idx\n",
    "\n",
    "        # print('led_num: ', led_ids[idx], ' dis:', '%0.18f' % temp_dis, ' : ',\n",
    "        #       points2D_reproj[idx][0], ' ', points2D_reproj[idx][1],\n",
    "        #       ' vs ', points2D[idx][0], ' ', points2D[idx][1])\n",
    "\n",
    "        if temp_dis > 100:\n",
    "            return ERROR, 0, 0, blob_array, except_inlier\n",
    "\n",
    "    trmse = float(rmse - dis)\n",
    "    # print('trmse : ', trmse, ' rmse : ', rmse)\n",
    "    if inliers is None:\n",
    "        return ERROR, -1, -1, blob_array, except_inlier\n",
    "    RER = round(np.sqrt(rmse) / len(inliers), 18)\n",
    "    if status == NOT_SET:\n",
    "        TRER = round(np.sqrt(trmse) / (len(inliers) - 1), 18)\n",
    "        if led_except == -1:\n",
    "            return ERROR, RER, TRER, blob_array, except_inlier\n",
    "    else:\n",
    "        TRER = round(np.sqrt(trmse) / (len(inliers)), 18)\n",
    "\n",
    "    for i, idx in enumerate(led_ids):\n",
    "        if idx != led_except:\n",
    "            blob_array.append({'idx': led_ids[i],\n",
    "                               'cx': points2D[i][0], 'cy': points2D[i][1], 'area': 0})\n",
    "\n",
    "    return SUCCESS, RER, TRER, blob_array, except_inlier\n",
    "\n",
    "\n",
    "def cal_iqr_func(arr):\n",
    "    Q1 = np.percentile(arr, 25)\n",
    "    Q3 = np.percentile(arr, 75)\n",
    "\n",
    "    IQR = Q3 - Q1\n",
    "\n",
    "    outlier_step = 1.5 * IQR\n",
    "\n",
    "    lower_bound = Q1 - outlier_step\n",
    "    upper_bound = Q3 + outlier_step\n",
    "\n",
    "    mask = np.where((arr > upper_bound) | (arr < lower_bound))\n",
    "\n",
    "    # print(f\"cal_iqr_func!!!!!! lower_bound = {lower_bound} upper_bound ={upper_bound} mask = {mask}\")\n",
    "\n",
    "    return mask\n",
    "\n",
    "\n",
    "def detect_outliers(idx, blob_array, remove_index_array):\n",
    "    temp_x = np.array(cal_iqr_func(blob_array[0]))\n",
    "    temp_y = np.array(cal_iqr_func(blob_array[1]))\n",
    "\n",
    "    for x in temp_x:\n",
    "        for xx in x:\n",
    "            if xx in remove_index_array:\n",
    "                continue\n",
    "            else:\n",
    "                remove_index_array.append(xx)\n",
    "    for y in temp_y:\n",
    "        for yy in y:\n",
    "            if yy in remove_index_array:\n",
    "                continue\n",
    "            else:\n",
    "                remove_index_array.append(yy)\n",
    "\n",
    "    remove_index_array.sort()\n",
    "\n",
    "    # print(\"detect_outliers!!!!!!!!!!!!!!!!!!!!!!!!!!!! remove_index_array\", remove_index_array)\n",
    "\n",
    "\n",
    "def median_blobs(cam_id, blob_array, rt_array):\n",
    "    blob_cnt = len(blob_array)\n",
    "    if blob_cnt == 0:\n",
    "        print('blob_cnt is 0')\n",
    "        return ERROR\n",
    "    blob_length = len(blob_array[0])\n",
    "\n",
    "    med_blobs_array = []\n",
    "    remove_index_array = []\n",
    "    med_rt_array = []\n",
    "    print('cam_id:', cam_id, ' blob_cnt:', blob_cnt)\n",
    "\n",
    "    for i in range(blob_length):\n",
    "        med_xy = [[], [], []]\n",
    "        for ii in range(blob_cnt):\n",
    "            med_xy[0].append(blob_array[ii][i]['cx'])\n",
    "            med_xy[1].append(blob_array[ii][i]['cy'])\n",
    "            # med_xy[2].append(blob_array[ii][i]['area'])\n",
    "        detect_outliers(blob_array[ii][i]['idx'], med_xy, remove_index_array)\n",
    "\n",
    "    r_len = len(remove_index_array)\n",
    "    print(f\"median_blobs!!!!! remove_index_array length={r_len}\")\n",
    "\n",
    "    for i in range(blob_length):\n",
    "        med_xy = [[], [], []]\n",
    "        for ii in range(blob_cnt):\n",
    "            med_xy[0].append(blob_array[ii][i]['cx'])\n",
    "            med_xy[1].append(blob_array[ii][i]['cy'])\n",
    "            # med_xy[2].append(blob_array[ii][i]['area'])\n",
    "        # tempx=med_xy[0]\n",
    "        # print(f\"original med_xy[0] = {tempx}\")\n",
    "        count = 0\n",
    "        for index in remove_index_array:\n",
    "            med_xy[0].pop(index - count)\n",
    "            med_xy[1].pop(index - count)\n",
    "            # med_xy[2].pop(index - count)\n",
    "            count += 1\n",
    "        # tempx=med_xy[0]\n",
    "        # print(f\"after pop med_xy[0] = {tempx}\")\n",
    "\n",
    "        mean_med_x = np.mean(med_xy[0])\n",
    "        mean_med_y = np.mean(med_xy[1])\n",
    "\n",
    "        med_blobs_array.append({'idx': blob_array[ii][i]['idx'],\n",
    "                                'cx': mean_med_x,\n",
    "                                'cy': mean_med_y})\n",
    "\n",
    "    if rt_array != NOT_SET:\n",
    "        count = 0\n",
    "        for index in remove_index_array:\n",
    "            rt_array.pop(index - count)\n",
    "            count += 1\n",
    "        for i in range(len(rt_array)):\n",
    "            rvt = [[], [], []]\n",
    "            for x in rt_array[i]['rvecs'][0]:\n",
    "                rvt[0].append(x)\n",
    "            for y in rt_array[i]['rvecs'][1]:\n",
    "                rvt[1].append(y)\n",
    "            for z in rt_array[i]['rvecs'][2]:\n",
    "                rvt[2].append(z)\n",
    "            tvt = [[], [], []]\n",
    "            for x in rt_array[i]['tvecs'][0]:\n",
    "                tvt[0].append(x)\n",
    "            for y in rt_array[i]['tvecs'][1]:\n",
    "                tvt[1].append(y)\n",
    "            for z in rt_array[i]['tvecs'][2]:\n",
    "                tvt[2].append(z)\n",
    "\n",
    "        mean_rvt = []\n",
    "        mean_tvt = []\n",
    "        for i in range(0, 3):\n",
    "            mean_rvt.append(np.mean(rvt[i]))\n",
    "            mean_tvt.append(np.mean(tvt[i]))\n",
    "\n",
    "        med_rt_array = {'rvecs': np.array([[mean_rvt[0]], [mean_rvt[1]], [mean_rvt[2]]], dtype=np.float64),\n",
    "                        'tvecs': np.array([[mean_tvt[0]], [mean_tvt[1]], [mean_tvt[2]]], dtype=np.float64)}\n",
    "\n",
    "        len_rt_array = len(rt_array)\n",
    "    #     print(f\"rt_array_len = {len_rt_array}\")\n",
    "    #     print(f\"med_rt_array = {med_rt_array}\")\n",
    "    # print(f\"med_blobs_array = {med_blobs_array}\")\n",
    "\n",
    "    blob_array = med_blobs_array\n",
    "\n",
    "    return blob_array, med_rt_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_center(frame, led_num, X, Y, W, H, blobs):\n",
    "    x_sum = 0\n",
    "    t_sum = 0\n",
    "    y_sum = 0\n",
    "    m_count = 0\n",
    "    g_c_x = 0\n",
    "    g_c_y = 0\n",
    "\n",
    "    ret_blobs = copy.deepcopy(blobs)\n",
    "\n",
    "    for y in range(Y, Y + H):\n",
    "        for x in range(X, X + W):\n",
    "            if frame[y][x] >= CV_MID_THRESHOLD:\n",
    "                x_sum += x * frame[y][x]\n",
    "                t_sum += frame[y][x]\n",
    "                m_count += 1\n",
    "\n",
    "    for x in range(X, X + W):\n",
    "        for y in range(Y, Y + H):\n",
    "            if frame[y][x] >= CV_MID_THRESHOLD:\n",
    "                y_sum += y * frame[y][x]\n",
    "\n",
    "    if t_sum != 0:\n",
    "        g_c_x = x_sum / t_sum\n",
    "        g_c_y = y_sum / t_sum\n",
    "\n",
    "    # print('led ', led_num, ' x ', g_c_x, ' y ', g_c_y)\n",
    "\n",
    "    if g_c_x == 0 or g_c_y == 0:\n",
    "        return ERROR\n",
    "\n",
    "    if len(ret_blobs) > 0:\n",
    "        detect = 0\n",
    "        for i, datas in enumerate(ret_blobs):\n",
    "            led = datas['idx']\n",
    "            if led == led_num:\n",
    "                ret_blobs[i] = {'idx': led_num, 'cx': g_c_x, 'cy': g_c_y}\n",
    "                detect = 1\n",
    "                break\n",
    "        if detect == 0:\n",
    "            ret_blobs.append({'idx': led_num, 'cx': g_c_x, 'cy': g_c_y})\n",
    "    else:\n",
    "        ret_blobs.append({'idx': led_num, 'cx': g_c_x, 'cy': g_c_y})\n",
    "\n",
    "    return DONE, ret_blobs\n",
    "\n",
    "\n",
    "def view_camera_infos(frame, text, x, y):\n",
    "    cv2.putText(frame, text,\n",
    "                (x, y),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), lineType=cv2.LINE_AA)\n",
    "\n",
    "\n",
    "trackerTypes = ['BOOSTING', 'MIL', 'KCF', 'TLD', 'MEDIANFLOW', 'GOTURN', 'MOSSE', 'CSRT']\n",
    "\n",
    "\n",
    "def createTrackerByName(trackerType):\n",
    "    # Create a tracker based on tracker name\n",
    "    if trackerType == trackerTypes[0]:\n",
    "        tracker = cv2.legacy.TrackerBoosting_create()\n",
    "    elif trackerType == trackerTypes[1]:\n",
    "        tracker = cv2.legacy.TrackerMIL_create()\n",
    "    elif trackerType == trackerTypes[2]:\n",
    "        tracker = cv2.legacy.TrackerKCF_create()\n",
    "    elif trackerType == trackerTypes[3]:\n",
    "        tracker = cv2.legacy.TrackerTLD_create()\n",
    "    elif trackerType == trackerTypes[4]:\n",
    "        tracker = cv2.legacy.TrackerMedianFlow_create()\n",
    "    elif trackerType == trackerTypes[5]:\n",
    "        tracker = cv2.legacy.TrackerGOTURN_create()\n",
    "    elif trackerType == trackerTypes[6]:\n",
    "        tracker = cv2.TrackerMOSSE_create()\n",
    "    elif trackerType == trackerTypes[7]:\n",
    "        tracker = cv2.legacy.TrackerCSRT_create()\n",
    "    else:\n",
    "        tracker = None\n",
    "        print('Incorrect tracker name')\n",
    "        print('Available trackers are:')\n",
    "        for t in trackerTypes:\n",
    "            print(t)\n",
    "\n",
    "    return tracker\n",
    "\n",
    "\n",
    "def camera_rt_test():\n",
    "    bboxes = []\n",
    "    blobs = []\n",
    "\n",
    "    for cam_id in range(len(leds_dic['cam_info'])):\n",
    "        print('try to open:', leds_dic['cam_info'][cam_id]['port'])\n",
    "        video_src = leds_dic['cam_info'][cam_id]['port']\n",
    "\n",
    "        cap = cv2.VideoCapture(video_src)\n",
    "        cap.set(cv2.CAP_PROP_FRAME_WIDTH, CAP_PROP_FRAME_WIDTH)\n",
    "        cap.set(cv2.CAP_PROP_FRAME_HEIGHT, CAP_PROP_FRAME_HEIGHT)\n",
    "        cap.set(cv2.CAP_PROP_FORMAT, cv2.CV_64FC1)\n",
    "\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                print('Cannot read video file')\n",
    "                break\n",
    "\n",
    "            img_draw = frame.copy()\n",
    "\n",
    "            if cv2.waitKey(1) == ord('a'):\n",
    "                view_camera_infos(frame, 'drag led area and press space bar',\n",
    "                                  30, 35)\n",
    "                cv2.imshow('MultiTracker', frame)\n",
    "                bbox = cv2.selectROI('MultiTracker', frame)\n",
    "                print(\"Press q to quit selecting boxes and start tracking\")\n",
    "                print(\"Press any other key to select next object\")\n",
    "                view_camera_infos(frame, 'press led numer',\n",
    "                                  30, 70)\n",
    "                cv2.imshow('MultiTracker', frame)\n",
    "                while True:\n",
    "                    # ToDo 수정해야 함\n",
    "                    key = cv2.waitKey(1) & 0xff\n",
    "                    if key in range(48, 58):  # 0~9 숫자 입력   ---⑥\n",
    "                        IDX = key - 48  # 선택한 숫자로 트랙커 인덱스 수정\n",
    "                        print('led num ', IDX)\n",
    "                        bboxes.append({'idx': IDX, 'bbox': bbox})\n",
    "                        break\n",
    "                    elif cv2.waitKey(1) == ord('q'):\n",
    "                        bboxes.clear()\n",
    "                        break\n",
    "\n",
    "            elif cv2.waitKey(1) == ord('n'):\n",
    "                break\n",
    "\n",
    "            elif cv2.waitKey(1) & 0xFF == 27:  # Esc pressed\n",
    "                cap.release()\n",
    "                cv2.destroyAllWindows()\n",
    "                return\n",
    "\n",
    "            if len(bboxes) > 0:\n",
    "                for i, data in enumerate(bboxes):\n",
    "                    (x, y, w, h) = data['bbox']\n",
    "                    IDX = data['idx']\n",
    "                    cv2.rectangle(img_draw, (int(x), int(y)), (int(x + w), int(y + h)), (0, 255, 0), 1)\n",
    "                    view_camera_infos(img_draw, ''.join([f'{IDX}']), int(x), int(y) - 10)\n",
    "                    view_camera_infos(img_draw, ''.join(['[', f'{IDX}', '] '\n",
    "                                                            , f' {x}'\n",
    "                                                            , f' {y}']), 30, 35 + i * 30)\n",
    "\n",
    "            view_camera_infos(img_draw, ''.join(['Cam[', f'{cam_id}', '] ', f'{video_src}']),\n",
    "                              CAP_PROP_FRAME_WIDTH - 250, 35)\n",
    "\n",
    "            cv2.circle(img_draw, (int(CAP_PROP_FRAME_WIDTH / 2), int(CAP_PROP_FRAME_HEIGHT / 2)), 2, color=(0, 0, 255),\n",
    "                       thickness=-1)\n",
    "\n",
    "            cv2.imshow('MultiTracker', img_draw)\n",
    "\n",
    "        # end while\n",
    "        print('Selected bounding boxes {}'.format(bboxes))\n",
    "\n",
    "        # Specify the tracker type\n",
    "        trackerType = \"CSRT\"\n",
    "\n",
    "        # Create MultiTracker object\n",
    "        multiTracker = cv2.legacy.MultiTracker_create()\n",
    "\n",
    "        tracker_start = 0\n",
    "        recording_start = 0\n",
    "\n",
    "        # Process video and track objects\n",
    "        while cap.isOpened():\n",
    "            success, frame = cap.read()\n",
    "            if not success:\n",
    "                break\n",
    "\n",
    "            ret, img_contour_binary = cv2.threshold(frame, CV_FINDCONTOUR_LVL, CV_MAX_THRESHOLD, cv2.THRESH_TOZERO)\n",
    "            img_gray = cv2.cvtColor(img_contour_binary, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            # Initialize MultiTracker\n",
    "            if tracker_start == 0:\n",
    "                for i, data in enumerate(bboxes):\n",
    "                    multiTracker.add(createTrackerByName(trackerType), img_gray, data['bbox'])\n",
    "\n",
    "            tracker_start = 1\n",
    "\n",
    "            # get updated location of objects in subsequent frames\n",
    "            qq, boxes = multiTracker.update(img_gray)\n",
    "\n",
    "            # draw tracked objects\n",
    "            for i, newbox in enumerate(boxes):\n",
    "                p1 = (int(newbox[0]), int(newbox[1]))\n",
    "                p2 = (int(newbox[0] + newbox[2]), int(newbox[1] + newbox[3]))\n",
    "                cv2.rectangle(img_gray, p1, p2, 255, 1)\n",
    "                IDX = bboxes[i]['idx']\n",
    "                view_camera_infos(img_gray, ''.join([f'{IDX}']), int(newbox[0]), int(newbox[1]) - 10)\n",
    "\n",
    "            KEY = cv2.waitKey(1)\n",
    "\n",
    "            # add graysum find center\n",
    "            for i, newbox in enumerate(boxes):\n",
    "                IDX = bboxes[i]['idx']\n",
    "                ret, new_blobs = find_center(img_gray, IDX, int(newbox[0]), int(newbox[1]),\n",
    "                                             int(newbox[2]), int(newbox[3]), blobs)\n",
    "                if ret == DONE:\n",
    "                    blobs = new_blobs\n",
    "\n",
    "            # ToDo\n",
    "            if ret == DONE:\n",
    "                ret_status, min_blob = simple_solvePNP(cam_id, frame, blobs)\n",
    "                if ret_status == SUCCESS:\n",
    "                    leds_dic['cam_info'][cam_id]['blobs'] = min_blob\n",
    "                    leds_dic['cam_info'][cam_id]['med_blobs'].append(min_blob)\n",
    "\n",
    "                    cv2.rectangle(img_gray, (10, 10), (CAP_PROP_FRAME_WIDTH - 10, CAP_PROP_FRAME_HEIGHT - 10), 255, 2)\n",
    "                    cam_ori = R.from_rotvec(leds_dic['cam_info'][cam_id]['RER']['C_R_T']['rvecs'].reshape(3)).as_quat()\n",
    "                    cam_ori_euler = np.round_(get_euler_from_quat('xyz', cam_ori), 3)\n",
    "                    cam_ori_quat = np.round_(get_quat_from_euler('xyz', cam_ori_euler), 8)\n",
    "                    cam_pos = leds_dic['cam_info'][cam_id]['RER']['C_R_T']['tvecs'].reshape(3)\n",
    "                    cv2.putText(img_gray, ''.join(['rot 'f'{cam_ori_euler}']),\n",
    "                                (20, 35),\n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 0.6, 255, lineType=cv2.LINE_AA)\n",
    "                    cv2.putText(img_gray, ''.join(['quat 'f'{cam_ori_quat}']),\n",
    "                                (20, 65),\n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 0.6, 255, lineType=cv2.LINE_AA)\n",
    "                    cv2.putText(img_gray, ''.join(['pos 'f'{cam_pos}']),\n",
    "                                (20, 95),\n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 0.6, 255, lineType=cv2.LINE_AA)\n",
    "                stacked = len(leds_dic['cam_info'][cam_id]['med_blobs'])\n",
    "                cv2.putText(img_gray, ''.join([f'{stacked}', ' data stacked']),\n",
    "                            (20, 125),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.6, 255, lineType=cv2.LINE_AA)\n",
    "\n",
    "            # quit on ESC button\n",
    "            if KEY & 0xFF == 27:  # Esc pressed\n",
    "                cap.release()\n",
    "                cv2.destroyAllWindows()\n",
    "                return\n",
    "            elif KEY == ord('e'):\n",
    "                break\n",
    "            elif KEY == ord('s'):\n",
    "                if recording_start == 0:\n",
    "                    # w = round(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "                    # h = round(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "                    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "                    # print('w', w, 'h', h, 'fps', fps)\n",
    "                    # fourcc  val 받아오기, *는 문자를 풀어쓰는 방식, *'DIVX' == 'D', 'I', 'V', 'X'\n",
    "                    delay = round(1000 / fps)\n",
    "                    now = datetime.datetime.now()\n",
    "                    recording_file_name = ''.join([f'{now}', '.avi'])\n",
    "                    print('recording start', ' ', recording_file_name)\n",
    "                    fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "                    recording_out = cv2.VideoWriter(recording_file_name, fourcc, fps,\n",
    "                                                    (CAP_PROP_FRAME_WIDTH, CAP_PROP_FRAME_HEIGHT))\n",
    "                    recording_start = 1\n",
    "\n",
    "                    leds_dic['cam_info'][cam_id]['track_cal']['recording'] = {'name': recording_file_name}\n",
    "\n",
    "            elif KEY == ord('c'):\n",
    "                blob_array, rt_array = median_blobs(cam_id,\n",
    "                                                    leds_dic['cam_info'][cam_id]['med_blobs'],\n",
    "                                                    leds_dic['cam_info'][cam_id]['D_R_T_A'])\n",
    "\n",
    "                leds_dic['cam_info'][cam_id]['track_cal']['data'] = {'idx': cam_id, 'blobs': blob_array,\n",
    "                                                                     'R_T': rt_array}\n",
    "\n",
    "                leds_dic['cam_info'][cam_id]['med_blobs'].clear()\n",
    "                leds_dic['cam_info'][cam_id]['D_R_T_A'].clear()\n",
    "\n",
    "                print(leds_dic['cam_info'][cam_id]['track_cal'])\n",
    "\n",
    "                if recording_start == 1:\n",
    "                    recording_out.release()\n",
    "                    recording_start = 0\n",
    "                break\n",
    "\n",
    "            # print current stacked data\n",
    "            for i, track_data in enumerate(leds_dic['cam_info'][cam_id]['track_cal']['data']):\n",
    "                track_r = R.from_rotvec(track_data['R_T']['rvecs'].reshape(3)).as_quat()\n",
    "                track_r_euler = np.round_(get_euler_from_quat('xyz', track_r), 3)\n",
    "                track_t = track_data['R_T']['tvecs'].reshape(3)\n",
    "                cv2.putText(img_gray, ''.join(['R 'f'{track_r_euler}',\n",
    "                                               ' T 'f'{track_t}']),\n",
    "                            (CAP_PROP_FRAME_WIDTH - 400, 35 + i * 20),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.3, 255, lineType=cv2.LINE_AA)\n",
    "\n",
    "            if recording_start == 1:\n",
    "                recording_out.write(frame)\n",
    "\n",
    "            # show frame\n",
    "            cv2.imshow('MultiTracker', img_gray)\n",
    "\n",
    "            # release camera frame\n",
    "        if recording_start == 1:\n",
    "            recording_out.release()\n",
    "\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "        bboxes.clear()\n",
    "        blobs.clear()\n",
    "\n",
    "\n",
    "def rectification(imgL, imgR, l_map, r_map):\n",
    "    img_left = imgL.copy()\n",
    "    img_right = imgR.copy()\n",
    "    Left_nice = cv2.remap(img_left, l_map[0], l_map[1], cv2.INTER_LANCZOS4, cv2.BORDER_CONSTANT, 0)\n",
    "    Right_nice = cv2.remap(img_right, r_map[0], r_map[1], cv2.INTER_LANCZOS4, cv2.BORDER_CONSTANT, 0)\n",
    "    return Left_nice, Right_nice\n",
    "\n",
    "\n",
    "def disparity_map(imgL, imgR):\n",
    "    window_size = 3\n",
    "\n",
    "    left_matcher = cv2.StereoSGBM_create(minDisparity=0, numDisparities=160,\n",
    "                                         blockSize=25,\n",
    "                                         P1=8 * 3 * window_size ** 2,\n",
    "                                         P2=32 * 3 * window_size ** 2,\n",
    "                                         disp12MaxDiff=1,\n",
    "                                         uniquenessRatio=15,\n",
    "                                         speckleWindowSize=0,\n",
    "                                         speckleRange=2,\n",
    "                                         preFilterCap=63,\n",
    "                                         mode=cv2.STEREO_SGBM_MODE_SGBM_3WAY\n",
    "                                         )\n",
    "\n",
    "    right_matcher = cv2.ximgproc.createRightMatcher(left_matcher)\n",
    "\n",
    "    lmbda = 80000\n",
    "    sigma = 1.2\n",
    "    visual_multiplyer = 1.0\n",
    "\n",
    "    wls_filter = cv2.ximgproc.createDisparityWLSFilter(matcher_left=left_matcher)\n",
    "    wls_filter.setLambda(lmbda)\n",
    "    wls_filter.setSigmaColor(sigma)\n",
    "\n",
    "    disp_left = left_matcher.compute(imgL, imgR)\n",
    "    disp_right = right_matcher.compute(imgR, imgL)\n",
    "    disp_left = np.int16(disp_left)\n",
    "    disp_right = np.int16(disp_right)\n",
    "\n",
    "    disp = wls_filter.filter(disp_left, imgL, None, disp_right)\n",
    "    disp = cv2.normalize(src=disp, dst=disp,\n",
    "                         beta=0, alpha=255, norm_type=cv2.NORM_MINMAX)\n",
    "    disp = np.uint8(disp)\n",
    "\n",
    "    return disp\n",
    "\n",
    "\n",
    "ply_header = '''ply\n",
    "format ascii 1.0\n",
    "element vertex %(vert_num)d\n",
    "property float x\n",
    "property float y\n",
    "property float z\n",
    "property uchar red\n",
    "property uchar green\n",
    "property uchar blue\n",
    "end_header\n",
    "'''\n",
    "\n",
    "\n",
    "def write_ply(fn, verts, colors):\n",
    "    verts = verts.reshape(-1, 3)\n",
    "    colors = colors.reshape(-1, 3)\n",
    "    verts = np.hstack([verts, colors])\n",
    "    with open(fn, 'wb') as f:\n",
    "        f.write((ply_header % dict(vert_num=len(verts))).encode('utf-8'))\n",
    "        np.savetxt(f, verts, fmt='%f %f %f %d %d %d ')\n",
    "\n",
    "\n",
    "def make_point_3d(jdata, disp, imgL, imgR):\n",
    "    Q = np.float32([jdata['stereoRectify']['Q'][0],\n",
    "                    jdata['stereoRectify']['Q'][1],\n",
    "                    jdata['stereoRectify']['Q'][2],\n",
    "                    jdata['stereoRectify']['Q'][3]])\n",
    "    points = cv2.reprojectImageTo3D(disp, Q)\n",
    "    reflect_matrix = np.identity(3)\n",
    "    reflect_matrix[0] *= -1\n",
    "    points = np.matmul(points, reflect_matrix)\n",
    "\n",
    "    # extract colors from image\n",
    "    colors = cv2.cvtColor(imgL, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # filter by min disparity\n",
    "    mask = disp > disp.min()\n",
    "    out_points = points[mask]\n",
    "    out_colors = colors[mask]\n",
    "\n",
    "    # filter by dimension\n",
    "    idx = np.fabs(out_points[:, 0]) < 4.5\n",
    "    out_points = out_points[idx]\n",
    "    out_colors = out_colors.reshape(-1, 3)\n",
    "    out_colors = out_colors[idx]\n",
    "\n",
    "    write_ply('out.ply', out_points, out_colors)\n",
    "    print('%s saved' % 'out.ply')\n",
    "\n",
    "    reflected_pts = np.matmul(out_points, reflect_matrix)\n",
    "    projected_img, _ = cv2.projectPoints(reflected_pts, np.identity(3), np.array([0., 0., 0.]),\n",
    "                                         leds_dic['cam_info'][1]['cam_cal']['cameraK'],\n",
    "                                         leds_dic['cam_info'][1]['cam_cal']['dist_coeff'])\n",
    "\n",
    "    projected_img = projected_img.reshape(-1, 2)\n",
    "    blank_img = np.zeros(imgL.shape, 'uint8')\n",
    "    img_colors = imgR[mask][idx].reshape(-1, 3)\n",
    "\n",
    "    for i, pt in enumerate(projected_img):\n",
    "        pt_x = int(pt[0])\n",
    "        pt_y = int(pt[1])\n",
    "        if pt_x > 0 and pt_y > 0:\n",
    "            # use the BGR format to match the original image type\n",
    "            col = (int(img_colors[i, 2]), int(img_colors[i, 1]), int(img_colors[i, 0]))\n",
    "            cv2.circle(blank_img, (pt_x, pt_y), 1, col)\n",
    "\n",
    "    # h, w = imgL.shape[:2]\n",
    "    # f = 0.8 * w  # guess for focal length\n",
    "    # Q = np.float32([[1, 0, 0, -0.5 * w],\n",
    "    #                 [0, -1, 0, 0.5 * h],  # turn points 180 deg around x-axis,\n",
    "    #                 [0, 0, 0, -f],  # so that y-axis looks up\n",
    "    #                 [0, 0, 1, 0]])\n",
    "    # points = cv2.reprojectImageTo3D(disp, Q)\n",
    "    # colors = cv2.cvtColor(imgL, cv2.COLOR_BGR2RGB)\n",
    "    # mask = disp > disp.min()\n",
    "    # out_points = points[mask]\n",
    "    # out_colors = colors[mask]\n",
    "    # out_fn = 'out.ply'\n",
    "    # write_ply(out_fn, out_points, out_colors)\n",
    "    # print('%s saved' % out_fn)\n",
    "\n",
    "    return blank_img\n",
    "\n",
    "\n",
    "def stereo_camera_start():\n",
    "    print('start open_camera')\n",
    "    ret, l_map, r_map = rw_file_storage(READ, NOT_SET, NOT_SET)\n",
    "    # load json file\n",
    "    json_file = ''.join(['jsons/test_result/', f'{JSON_FILE}'])\n",
    "    jdata = rw_json_data(READ, json_file, None)\n",
    "\n",
    "    if ret == DONE:\n",
    "        cap1 = cv2.VideoCapture(leds_dic['cam_info'][0]['port'])\n",
    "        cap2 = cv2.VideoCapture(leds_dic['cam_info'][1]['port'])\n",
    "\n",
    "        cap1.set(cv2.CAP_PROP_FRAME_WIDTH, CAP_PROP_FRAME_WIDTH)\n",
    "        # cap1.set(cv2.CAP_PROP_FORMAT, cv2.CV_64FC1)\n",
    "\n",
    "        cap2.set(cv2.CAP_PROP_FRAME_WIDTH, CAP_PROP_FRAME_WIDTH)\n",
    "        cap2.set(cv2.CAP_PROP_FRAME_HEIGHT, CAP_PROP_FRAME_HEIGHT)\n",
    "        # cap2.set(cv2.CAP_PROP_FORMAT, cv2.CV_64FC1)\n",
    "\n",
    "        if not cap1.isOpened() or not cap2.isOpened():\n",
    "            sys.exit()\n",
    "        fps = cap1.get(cv2.CAP_PROP_FPS)\n",
    "        delay = int(1000 / fps)\n",
    "\n",
    "        while True:\n",
    "            ret1, frame1 = cap1.read()\n",
    "            ret2, frame2 = cap2.read()\n",
    "            if not ret1 or not ret2:\n",
    "                break\n",
    "            imgL = frame1.copy()\n",
    "            imgR = frame2.copy()\n",
    "\n",
    "            KEY = cv2.waitKey(1)\n",
    "\n",
    "            # show origin frame\n",
    "            alpha = 0.5\n",
    "            # origin_frame = cv2.addWeighted(imgL, alpha, imgR, alpha, 0)\n",
    "            # cv2.imshow('origin frame', origin_frame)\n",
    "\n",
    "            # Rectification\n",
    "            R_L_F, R_R_F = rectification(imgL, imgR, l_map, r_map)\n",
    "            out = R_R_F.copy()\n",
    "            out[:, :, 0] = R_R_F[:, :, 0]\n",
    "            out[:, :, 1] = R_R_F[:, :, 1]\n",
    "            out[:, :, 2] = R_L_F[:, :, 2]\n",
    "            cv2.imshow(\"rectification\", out)\n",
    "\n",
    "            # Disparity\n",
    "            disparity_frame = disparity_map(R_L_F, R_R_F)\n",
    "            cv2.imshow(\"disparity map\", disparity_frame)\n",
    "\n",
    "            if KEY == ord('c'):\n",
    "                # make 3d point cloud\n",
    "                point_cloud_frame = make_point_3d(jdata, disparity_frame, imgL, imgR)\n",
    "                cv2.imshow(\"point cloud\", point_cloud_frame)\n",
    "            elif cv2.waitKey(1) & 0xFF == 27:  # Esc pressed\n",
    "                break\n",
    "\n",
    "\n",
    "\n",
    "            cv2.waitKey(delay)\n",
    "\n",
    "        cap1.release()\n",
    "        cap2.release()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "        # Draw point cloud\n",
    "        try:\n",
    "            cloud = o3d.io.read_point_cloud(\"out.ply\")  # Read the point cloud\n",
    "            o3d.visualization.draw_geometries([cloud])\n",
    "        except:\n",
    "            print('error occured')\n",
    "\n",
    "\n",
    "def camera_setting():\n",
    "    print('start open_camera')\n",
    "\n",
    "    cap1 = cv2.VideoCapture(leds_dic['cam_info'][0]['port'])\n",
    "    cap1_name = leds_dic['cam_info'][0]['json']\n",
    "    cap2 = cv2.VideoCapture(leds_dic['cam_info'][1]['port'])\n",
    "    cap2_name = leds_dic['cam_info'][1]['json']\n",
    "\n",
    "    cap1.set(cv2.CAP_PROP_FRAME_WIDTH, CAP_PROP_FRAME_WIDTH)\n",
    "    cap1.set(cv2.CAP_PROP_FRAME_HEIGHT, CAP_PROP_FRAME_HEIGHT)\n",
    "    cap1.set(cv2.CAP_PROP_FORMAT, cv2.CV_64FC1)\n",
    "\n",
    "    cap2.set(cv2.CAP_PROP_FRAME_WIDTH, CAP_PROP_FRAME_WIDTH)\n",
    "    cap2.set(cv2.CAP_PROP_FRAME_HEIGHT, CAP_PROP_FRAME_HEIGHT)\n",
    "    cap2.set(cv2.CAP_PROP_FORMAT, cv2.CV_64FC1)\n",
    "\n",
    "    if not cap1.isOpened() or not cap2.isOpened():\n",
    "        sys.exit()\n",
    "    fps = cap1.get(cv2.CAP_PROP_FPS)\n",
    "    delay = int(1000 / fps)\n",
    "\n",
    "    while True:\n",
    "        ret1, frame1 = cap1.read()\n",
    "        ret2, frame2 = cap2.read()\n",
    "        if not ret1 or not ret2:\n",
    "            break\n",
    "        imgL = frame1.copy()\n",
    "        imgR = frame2.copy()\n",
    "        KEY = cv2.waitKey(1)\n",
    "        if cv2.waitKey(1) & 0xFF == 27:  # Esc pressed\n",
    "            break\n",
    "        view_camera_infos(imgL, f'{cap1_name}', 30, 35)\n",
    "        cv2.circle(imgL, (int(CAP_PROP_FRAME_WIDTH / 2), int(CAP_PROP_FRAME_HEIGHT / 2)), 2, color=(0, 0, 255),\n",
    "                   thickness=-1)\n",
    "        cv2.imshow('left camera', imgL)\n",
    "        view_camera_infos(imgR, f'{cap2_name}', 30, 35)\n",
    "        cv2.circle(imgR, (int(CAP_PROP_FRAME_WIDTH / 2), int(CAP_PROP_FRAME_HEIGHT / 2)), 2, color=(0, 0, 255),\n",
    "                   thickness=-1)\n",
    "        cv2.imshow(\"right camera\", imgR)\n",
    "\n",
    "        alpha = 0.5\n",
    "\n",
    "        after_frame = cv2.addWeighted(frame1, alpha, frame2, alpha, 0)\n",
    "        cv2.imshow('stereo camera', after_frame)\n",
    "\n",
    "        cv2.waitKey(delay)\n",
    "\n",
    "    cap1.release()\n",
    "    cap2.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "def compare_length(a, b):\n",
    "    if a >= b:\n",
    "        return b\n",
    "    else:\n",
    "        return a\n",
    "\n",
    "\n",
    "def get_points(blob_array):\n",
    "    model_points = []\n",
    "    image_points = []\n",
    "    led_ids = []\n",
    "\n",
    "    for blobs in blob_array:\n",
    "        led_num = int(blobs['idx'])\n",
    "        # if DEBUG == ENABLE:\n",
    "        #     print('idx:', led_num, ' added 3d', leds_dic['pts'][led_num]['pos'], ' remake: ',\n",
    "        #           leds_dic['target_pts'][led_num]['remake_3d'],\n",
    "        #           ' 2d', [blobs['cx'], blobs['cy']])\n",
    "\n",
    "        model_points.append(leds_dic['pts'][led_num]['pos'])\n",
    "        led_ids.append(led_num)\n",
    "        image_points.append([blobs['cx'], blobs['cy']])\n",
    "\n",
    "    model_points_len = len(model_points)\n",
    "    image_points_len = len(image_points)\n",
    "    # check assertion\n",
    "    if model_points_len != image_points_len:\n",
    "        print(\"assertion len is not equal\")\n",
    "        return ERROR, ERROR, ERROR\n",
    "\n",
    "    return led_ids, np.array(model_points), np.array(image_points)\n",
    "\n",
    "\n",
    "def stereo_calibrate():\n",
    "    try:\n",
    "        led_num_l, points3D_l, points2D_l = get_points(leds_dic['cam_info'][0]['track_cal']['data']['blobs'])\n",
    "        led_num_r, points3D_r, points2D_r = get_points(leds_dic['cam_info'][1]['track_cal']['data']['blobs'])\n",
    "\n",
    "        # ToDo\n",
    "        camera_k_l = leds_dic['cam_info'][0]['cam_cal']['cameraK']\n",
    "        dist_coeff_l = leds_dic['cam_info'][0]['cam_cal']['dist_coeff']\n",
    "\n",
    "        camera_k_r = leds_dic['cam_info'][1]['cam_cal']['cameraK']\n",
    "        dist_coeff_r = leds_dic['cam_info'][1]['cam_cal']['dist_coeff']\n",
    "\n",
    "        print('cam l info')\n",
    "        print(led_num_l)\n",
    "        print(points3D_l)\n",
    "        print(points2D_l)\n",
    "        print('cam r info')\n",
    "        print(led_num_r)\n",
    "        print(points3D_r)\n",
    "        print(points2D_r)\n",
    "\n",
    "        obj_points = []\n",
    "        img_points_l = []\n",
    "        img_points_r = []\n",
    "        length = len(led_num_l)\n",
    "        objectpoint = np.zeros((length, D3D), np.float32)\n",
    "        imgpointl = np.zeros((length, D2D), np.float32)\n",
    "        imgpointr = np.zeros((length, D2D), np.float32)\n",
    "\n",
    "        for idx, led_num in enumerate(led_num_l):\n",
    "            objectpoint[idx] = leds_dic['pts'][led_num]['pos']\n",
    "            imgpointl[idx] = points2D_l[idx]\n",
    "            imgpointr[idx] = points2D_r[idx]\n",
    "        obj_points.append(objectpoint)\n",
    "        img_points_l.append(imgpointl)\n",
    "        img_points_r.append(imgpointr)\n",
    "        print(obj_points)\n",
    "        print(img_points_l)\n",
    "        print(img_points_r)\n",
    "\n",
    "        flags = 0\n",
    "        flags |= cv2.CALIB_FIX_INTRINSIC\n",
    "        criteria_stereo = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
    "        ret, CM1, dist0, CM2, dist1, R, T, E, F = cv2.stereoCalibrate(obj_points, img_points_l, img_points_r,\n",
    "                                                                      camera_k_l, dist_coeff_l,\n",
    "                                                                      camera_k_r, dist_coeff_r,\n",
    "                                                                      (CAP_PROP_FRAME_WIDTH, CAP_PROP_FRAME_HEIGHT),\n",
    "                                                                      criteria_stereo,\n",
    "                                                                      flags)\n",
    "\n",
    "        print(CM1, ' ', dist0)\n",
    "        print(CM2, ' ', dist1)\n",
    "        print('R ', R, '\\nT ', T, '\\nE ', E, '\\nF ', F)\n",
    "\n",
    "        rectify_scale = 1\n",
    "        rect_l, rect_r, proj_mat_l, proj_mat_r, Q, roiL, roiR = cv2.stereoRectify(CM1, dist0, CM2, dist1,\n",
    "                                                                                  (CAP_PROP_FRAME_WIDTH,\n",
    "                                                                                   CAP_PROP_FRAME_HEIGHT),\n",
    "                                                                                  R, T,\n",
    "                                                                                  rectify_scale, (0, 0))\n",
    "\n",
    "        print('rect_l ', rect_l)\n",
    "        print('rect_r ', rect_r)\n",
    "        print('proj_mat_l ', proj_mat_l)\n",
    "        print('proj_mat_r ', proj_mat_r)\n",
    "\n",
    "        Left_Stereo_Map = cv2.initUndistortRectifyMap(CM1, dist0, rect_l, proj_mat_l,\n",
    "                                                      (CAP_PROP_FRAME_WIDTH, CAP_PROP_FRAME_HEIGHT), cv2.CV_16SC2)\n",
    "        Right_Stereo_Map = cv2.initUndistortRectifyMap(CM2, dist1, rect_r, proj_mat_r,\n",
    "                                                       (CAP_PROP_FRAME_WIDTH, CAP_PROP_FRAME_HEIGHT), cv2.CV_16SC2)\n",
    "\n",
    "        print('save rectification map')\n",
    "        rw_file_storage(WRITE, Left_Stereo_Map, Right_Stereo_Map)\n",
    "        json_file = ''.join(['jsons/test_result/', f'{JSON_FILE}'])\n",
    "        group_data = OrderedDict()\n",
    "        group_data['stereoRectify'] = {\n",
    "            'rect_l': rect_l.tolist(),\n",
    "            'rect_r': rect_r.tolist(),\n",
    "            'proj_mat_l': proj_mat_l.tolist(),\n",
    "            'proj_mat_r': proj_mat_r.tolist(),\n",
    "            'Q': Q.tolist()}\n",
    "        group_data['stereol'] = {'cam_id': leds_dic['cam_info'][0]['json'],\n",
    "                                 'blobs': leds_dic['cam_info'][0]['track_cal']['data']['blobs'],\n",
    "                                 'rvecs': leds_dic['cam_info'][0]['track_cal']['data']['R_T']['rvecs'][:,\n",
    "                                          0].tolist(),\n",
    "                                 'tvecs': leds_dic['cam_info'][0]['track_cal']['data']['R_T']['tvecs'][:,\n",
    "                                          0].tolist(),\n",
    "                                 'file': leds_dic['cam_info'][0]['track_cal']['recording']['name']}\n",
    "        group_data['stereor'] = {'cam_id': leds_dic['cam_info'][1]['json'],\n",
    "                                 'blobs': leds_dic['cam_info'][1]['track_cal']['data']['blobs'],\n",
    "                                 'rvecs': leds_dic['cam_info'][1]['track_cal']['data']['R_T']['rvecs'][:,\n",
    "                                          0].tolist(),\n",
    "                                 'tvecs': leds_dic['cam_info'][1]['track_cal']['data']['R_T']['tvecs'][:,\n",
    "                                          0].tolist(),\n",
    "                                 'file': leds_dic['cam_info'][1]['track_cal']['recording']['name']}\n",
    "        print('save stereo info')\n",
    "        rw_json_data(WRITE, json_file, group_data)\n",
    "\n",
    "        return DONE, Left_Stereo_Map, Right_Stereo_Map\n",
    "    except:\n",
    "        traceback.print_exc()\n",
    "        return ERROR, NOT_SET, NOT_SET\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rangkast.jeong/Project/OpenCV_APP/API_TEST\n",
      "/usr/lib/python38.zip\n",
      "/usr/lib/python3.8\n",
      "/usr/lib/python3.8/lib-dynload\n",
      "\n",
      "/home/rangkast.jeong/.local/lib/python3.8/site-packages\n",
      "/usr/local/lib/python3.8/dist-packages\n",
      "/usr/local/lib/python3.8/dist-packages/PyBluez-0.23-py3.8-linux-x86_64.egg\n",
      "/usr/lib/python3/dist-packages\n",
      "start  terminal_cmd\n",
      "done\n",
      "[{'id': b'8087:8000', 'tag': b'Intel Corp. ', 'device': \"/dev/bus/usb/b'002'/b'002'\"}, {'id': b'1d6b:0002', 'tag': b'Linux Foundation 2.0 root hub', 'device': \"/dev/bus/usb/b'002'/b'001'\"}, {'id': b'8087:8008', 'tag': b'Intel Corp. ', 'device': \"/dev/bus/usb/b'001'/b'002'\"}, {'id': b'1d6b:0002', 'tag': b'Linux Foundation 2.0 root hub', 'device': \"/dev/bus/usb/b'001'/b'001'\"}, {'id': b'2833:0211', 'tag': b' ', 'device': \"/dev/bus/usb/b'004'/b'004'\"}, {'id': b'2833:0211', 'tag': b' ', 'device': \"/dev/bus/usb/b'004'/b'003'\"}, {'id': b'2109:0820', 'tag': b'VIA Labs, Inc. USB3.1 Hub             ', 'device': \"/dev/bus/usb/b'004'/b'002'\"}, {'id': b'1d6b:0003', 'tag': b'Linux Foundation 3.0 root hub', 'device': \"/dev/bus/usb/b'004'/b'001'\"}, {'id': b'1004:631d', 'tag': b'LG Electronics, Inc. Optimus Android Phone (Camera/PTP Mode)', 'device': \"/dev/bus/usb/b'003'/b'009'\"}, {'id': b'1004:631d', 'tag': b'LG Electronics, Inc. Optimus Android Phone (Camera/PTP Mode)', 'device': \"/dev/bus/usb/b'003'/b'010'\"}, {'id': b'2109:2820', 'tag': b'VIA Labs, Inc. USB2.0 Hub             ', 'device': \"/dev/bus/usb/b'003'/b'004'\"}, {'id': b'8087:07da', 'tag': b'Intel Corp. ', 'device': \"/dev/bus/usb/b'003'/b'003'\"}, {'id': b'0853:0134', 'tag': b'Topre Corporation Mini Keyboard', 'device': \"/dev/bus/usb/b'003'/b'005'\"}, {'id': b'046d:c52f', 'tag': b'Logitech, Inc. Unifying Receiver', 'device': \"/dev/bus/usb/b'003'/b'002'\"}, {'id': b'1d6b:0002', 'tag': b'Linux Foundation 2.0 root hub', 'device': \"/dev/bus/usb/b'003'/b'001'\"}]\n",
      "==================================================\n",
      "skipping camera Droidcam (platform:v4l2loopback_dc-000):\n",
      "\t/dev/video0\n",
      "\t/dev/video1\n",
      "add list rift_sensor Rift Sensor: CV1 External Camer (usb-0000:00:14.0-5.1):\n",
      "\t/dev/video2\n",
      "\t/dev/video3\n",
      "\t/dev/media0\n",
      "add list rift_sensor Rift Sensor: CV1 External Camer (usb-0000:00:14.0-5.2):\n",
      "\t/dev/video4\n",
      "\t/dev/video5\n",
      "\t/dev/media1\n",
      "skipping camera \n",
      "==================================================\n",
      "start  init_model_json\n",
      "['Rift Sensor: CV1 External Camer (usb-0000:00:14.0-5.1):\\n\\t/dev/video2\\n\\t/dev/video3\\n\\t/dev/media0', 'Rift Sensor: CV1 External Camer (usb-0000:00:14.0-5.2):\\n\\t/dev/video4\\n\\t/dev/video5\\n\\t/dev/media1']  count: 2\n",
      "\n",
      "\n",
      "cam_id[ 0 ] : WMTD307H601E9L.json\n",
      "cameraK:  [[712.991   0.    640.721]\n",
      " [  0.    712.991 478.511]\n",
      " [  0.      0.      1.   ]]\n",
      "dist_coeff:  [[ 0.075313]\n",
      " [-0.028047]\n",
      " [ 0.007603]\n",
      " [-0.00096 ]]\n",
      "cam_info:  ['Rift Sensor: CV1 External Camer (usb-0000:00:14.0-5.1):', '/dev/video2', '/dev/video3', '/dev/media0']\n",
      "\n",
      "\n",
      "cam_id[ 1 ] : WMTD302J600GA9.json\n",
      "cameraK:  [[714.193   0.    636.242]\n",
      " [  0.    714.193 468.407]\n",
      " [  0.      0.      1.   ]]\n",
      "dist_coeff:  [[ 0.072888]\n",
      " [-0.02417 ]\n",
      " [ 0.005435]\n",
      " [-0.000575]]\n",
      "cam_info:  ['Rift Sensor: CV1 External Camer (usb-0000:00:14.0-5.2):', '/dev/video4', '/dev/video5', '/dev/media1']\n",
      "done\n",
      "start  init_coord_json\n",
      "{ .pos = {{0.03300807,0.00371497,0.00026865 }}, .dir={{0.7051038,-0.6950803,0.14032818 }}, .pattern=12},\n",
      "{ .pos = {{0.04222733,0.0228845,-0.00394005 }}, .dir={{0.9435189,-0.10477919,-0.31431419 }}, .pattern=11},\n",
      "{ .pos = {{0.02000199,-0.00388647,-0.014973 }}, .dir={{0.49720891,-0.70839529,-0.5009585 }}, .pattern=14},\n",
      "{ .pos = {{0.03006234,0.00378822,-0.01297127 }}, .dir={{0.67315478,-0.5810967,-0.45737213 }}, .pattern=13},\n",
      "{ .pos = {{0.04265723,0.03016438,0.01624689 }}, .dir={{0.90904575,-0.17393345,0.37865945 }}, .pattern=10},\n",
      "{ .pos = {{-0.02146761,-0.00343424,-0.01381839 }}, .dir={{-0.52706841,-0.71386452,-0.46108171 }}, .pattern=0},\n",
      "{ .pos = {{-0.0318701,0.00568587,-0.01206734 }}, .dir={{-0.71941994,-0.53832866,-0.43890456 }}, .pattern=1},\n",
      "{ .pos = {{-0.03692925,0.00930785,0.00321071 }}, .dir={{-0.75763735,-0.6234486,0.19312559 }}, .pattern=2},\n",
      "{ .pos = {{-0.04287211,0.02691347,-0.00194137 }}, .dir={{-0.95565641,0.00827838,-0.29436762 }}, .pattern=3},\n",
      "{ .pos = {{-0.04170018,0.03609551,0.01989264 }}, .dir={{-0.89943476,-0.04857372,0.43434745 }}, .pattern=4},\n",
      "{ .pos = {{-0.02923584,0.06186962,0.0161972 }}, .dir={{-0.57938915,0.80424722,-0.13226727 }}, .pattern=5},\n",
      "{ .pos = {{-0.01456789,0.06295633,0.03659283 }}, .dir={{-0.32401356,0.5869508,0.74195955 }}, .pattern=6},\n",
      "{ .pos = {{0.00766914,0.07115411,0.0206431 }}, .dir={{0.14082806,0.97575588,-0.16753482 }}, .pattern=7},\n",
      "{ .pos = {{0.02992447,0.05507271,0.03108736 }}, .dir={{0.66436362,0.41503629,0.62158335 }}, .pattern=8},\n",
      "{ .pos = {{0.03724313,0.05268665,0.01100446 }}, .dir={{0.77126662,0.61174447,-0.17583089 }}, .pattern=9},\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "# TEST Code \n",
    "cam_dev_list = terminal_cmd('v4l2-ctl', '--list-devices')\n",
    "leds_dic['cam_info'] = init_model_json(cam_dev_list)\n",
    "leds_dic['pts'] = init_coord_json(ORIGIN)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start open_camera\n"
     ]
    }
   ],
   "source": [
    "# ToDo make stereo camera and calibration\n",
    "camera_setting()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "try to open: /dev/video2\n"
     ]
    }
   ],
   "source": [
    "camera_rt_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19477/1035423016.py\", line 589, in stereo_calibrate\n",
      "    led_num_l, points3D_l, points2D_l = get_points(leds_dic['cam_info'][0]['track_cal']['data']['blobs'])\n",
      "TypeError: list indices must be integers or slices, not str\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(-1, 'NOT_SET', 'NOT_SET')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stereo_calibrate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ERROR:0@12.344] global /io/opencv/modules/core/src/persistence.cpp (505) open Can't open file: 'improved_params2.xml' in read mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start open_camera\n",
      "READ parameters ......\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.6.0) /io/opencv/modules/imgproc/src/imgwarp.cpp:1703: error: (-215:Assertion failed) !_map1.empty() in function 'remap'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mstereo_camera_start\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn [4], line 468\u001b[0m, in \u001b[0;36mstereo_camera_start\u001b[0;34m()\u001b[0m\n\u001b[1;32m    463\u001b[0m alpha \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.5\u001b[39m\n\u001b[1;32m    464\u001b[0m \u001b[38;5;66;03m# origin_frame = cv2.addWeighted(imgL, alpha, imgR, alpha, 0)\u001b[39;00m\n\u001b[1;32m    465\u001b[0m \u001b[38;5;66;03m# cv2.imshow('origin frame', origin_frame)\u001b[39;00m\n\u001b[1;32m    466\u001b[0m \n\u001b[1;32m    467\u001b[0m \u001b[38;5;66;03m# Rectification\u001b[39;00m\n\u001b[0;32m--> 468\u001b[0m R_L_F, R_R_F \u001b[38;5;241m=\u001b[39m \u001b[43mrectification\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimgL\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimgR\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ml_map\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mr_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    469\u001b[0m out \u001b[38;5;241m=\u001b[39m R_R_F\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m    470\u001b[0m out[:, :, \u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m R_R_F[:, :, \u001b[38;5;241m0\u001b[39m]\n",
      "Cell \u001b[0;32mIn [4], line 302\u001b[0m, in \u001b[0;36mrectification\u001b[0;34m(imgL, imgR, l_map, r_map)\u001b[0m\n\u001b[1;32m    300\u001b[0m img_left \u001b[38;5;241m=\u001b[39m imgL\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m    301\u001b[0m img_right \u001b[38;5;241m=\u001b[39m imgR\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m--> 302\u001b[0m Left_nice \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mremap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_left\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ml_map\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ml_map\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mINTER_LANCZOS4\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBORDER_CONSTANT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    303\u001b[0m Right_nice \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mremap(img_right, r_map[\u001b[38;5;241m0\u001b[39m], r_map[\u001b[38;5;241m1\u001b[39m], cv2\u001b[38;5;241m.\u001b[39mINTER_LANCZOS4, cv2\u001b[38;5;241m.\u001b[39mBORDER_CONSTANT, \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    304\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Left_nice, Right_nice\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.6.0) /io/opencv/modules/imgproc/src/imgwarp.cpp:1703: error: (-215:Assertion failed) !_map1.empty() in function 'remap'\n"
     ]
    }
   ],
   "source": [
    "stereo_camera_start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test code\n",
      "cam_id  0\n",
      "{'data': {'idx': 0, 'blobs': [{'idx': 0, 'cx': 673.351120200472, 'cy': 485.7315649230365}, {'idx': 1, 'cx': 659.5054466320646, 'cy': 498.94471391905245}, {'idx': 2, 'cx': 636.6083708452054, 'cy': 477.4618826199966}, {'idx': 3, 'cx': 610.9405008424263, 'cy': 508.63246776777936}, {'idx': 4, 'cx': 571.7110761405204, 'cy': 477.7504154303324}, {'idx': 5, 'cx': 522.9846662561289, 'cy': 506.1850928203594}], 'R_T': {'rvecs': array([[ 0.94183797],\n",
      "       [-1.64508934],\n",
      "       [ 0.73118163]]), 'tvecs': array([[ 0.00238048],\n",
      "       [-0.01088951],\n",
      "       [ 0.3658937 ]])}}, 'recording': {'name': 'NOT_SET'}}\n",
      "cam_id  1\n",
      "{'data': {'idx': 1, 'blobs': [{'idx': 0, 'cx': 680.3836305265489, 'cy': 488.1642043433271}, {'idx': 1, 'cx': 659.9335375427876, 'cy': 501.76220748348254}, {'idx': 2, 'cx': 638.5125387615051, 'cy': 479.6488566891384}, {'idx': 3, 'cx': 607.2507483377221, 'cy': 507.90989836271746}, {'idx': 4, 'cx': 568.356018311576, 'cy': 474.0671326378273}, {'idx': 5, 'cx': 530.3440358644713, 'cy': 492.9537335926129}], 'R_T': {'rvecs': array([[ 1.16302643],\n",
      "       [-1.47056274],\n",
      "       [ 0.5988484 ]]), 'tvecs': array([[ 0.01418876],\n",
      "       [-0.00813484],\n",
      "       [ 0.36092625]])}}, 'recording': {'name': 'NOT_SET'}}\n"
     ]
    }
   ],
   "source": [
    "print('Test code')\n",
    "\n",
    "for data in leds_dic['cam_info']:\n",
    "    print('cam_id ', data['idx'])\n",
    "    print(data['track_cal'])\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
