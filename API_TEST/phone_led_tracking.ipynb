{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "import signal\n",
    "from collections import OrderedDict\n",
    "from dataclasses import dataclass\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "import numpy as np\n",
    "import subprocess\n",
    "from operator import itemgetter, attrgetter\n",
    "import re\n",
    "import subprocess\n",
    "import cv2\n",
    "import traceback\n",
    "import math\n",
    "import os\n",
    "import sys\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class vector3:\n",
    "    x: float = 0.0\n",
    "    y: float = 0.0\n",
    "    z: float = 0.0\n",
    "\n",
    "    def __array__(self) -> np.ndarray:\n",
    "        return np.array([self.x, self.y, self.z])\n",
    "\n",
    "    def clamp(self, mmin, mmax):\n",
    "        self.x = max(mmin, self.x)\n",
    "        self.x = min(mmax, self.x)\n",
    "        self.y = max(mmin, self.y)\n",
    "        self.y = min(mmax, self.y)\n",
    "        self.z = max(mmin, self.z)\n",
    "        self.z = min(mmax, self.z)\n",
    "\n",
    "    def mult_me(self, d):\n",
    "        self.x *= d\n",
    "        self.y *= d\n",
    "        self.z *= d\n",
    "\n",
    "    def normalize_me(self):\n",
    "        if self.x == 0 and self.y == 0 and self.z == 0:\n",
    "            return\n",
    "        len = self.get_length()\n",
    "        # print('1: ', self.x, ' ', self.y, ' ', self.z, ' ', len)\n",
    "        self.x /= len\n",
    "        self.y /= len\n",
    "        self.z /= len\n",
    "        # print('2: ', self.x, ' ', self.y, ' ', self.z, ' ', len)\n",
    "        return vector3(self.x, self.y, self.z)\n",
    "\n",
    "    def get_length(self):\n",
    "        return np.sqrt(np.sum(np.power(np.array(self), 2)))\n",
    "\n",
    "    def copy(self):\n",
    "        return vector3(self.x, self.y, self.z)\n",
    "\n",
    "    def round(self, d):\n",
    "        self.x = round(self.x, d)\n",
    "        self.y = round(self.y, d)\n",
    "        self.z = round(self.z, d)\n",
    "\n",
    "    def round_(self, d):\n",
    "        return vector3(round(self.x, d), round(self.y, d), round(self.z, d))\n",
    "\n",
    "    def get_rotated(self, tq):\n",
    "        q = quat(self.x * tq.w + self.z * tq.y - self.y * tq.z,\n",
    "                 self.y * tq.w + self.x * tq.z - self.z * tq.x,\n",
    "                 self.z * tq.w + self.y * tq.x - self.x * tq.y,\n",
    "                 self.x * tq.x + self.y * tq.y + self.z * tq.z)\n",
    "        return vector3(tq.w * q.x + tq.x * q.w + tq.y * q.z - tq.z * q.y,\n",
    "                       tq.w * q.y + tq.y * q.w + tq.z * q.x - tq.x * q.z,\n",
    "                       tq.w * q.z + tq.z * q.w + tq.x * q.y - tq.y * q.x)\n",
    "\n",
    "    def add_vector3(self, t):\n",
    "        return vector3(round(self.x + t.x, 8), round(self.y + t.y, 8), round(self.z + t.z, 8))\n",
    "\n",
    "    def sub_vector3(self, t):\n",
    "        return vector3(round(self.x - t.x, 8), round(self.y - t.y, 8), round(self.z - t.z, 8))\n",
    "\n",
    "    def get_dot(self, t):\n",
    "        return self.x * t.x + self.y * t.y + self.z * t.z\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class quat:\n",
    "    x: float = 0.0\n",
    "    y: float = 0.0\n",
    "    z: float = 0.0\n",
    "    w: float = 1.0\n",
    "\n",
    "    def __array__(self) -> np.ndarray:\n",
    "        return np.array([self.x, self.y, self.z, self.w])\n",
    "\n",
    "    def mult_me_quat(self, q):\n",
    "        tmp = self.copy()\n",
    "        self.x = tmp.w * q.x + tmp.x * q.w + tmp.y * q.z - tmp.z * q.y\n",
    "        self.y = tmp.w * q.y - tmp.x * q.z + tmp.y * q.w + tmp.z * q.x\n",
    "        self.z = tmp.w * q.z + tmp.x * q.y - tmp.y * q.x + tmp.z * q.w\n",
    "        self.w = tmp.w * q.w - tmp.x * q.x - tmp.y * q.y - tmp.z * q.z\n",
    "\n",
    "    def mult_quat(self, q):\n",
    "        tmp = self.copy()\n",
    "        return quat(tmp.w * q.x + tmp.x * q.w + tmp.y * q.z - tmp.z * q.y,\n",
    "                    tmp.w * q.y - tmp.x * q.z + tmp.y * q.w + tmp.z * q.x,\n",
    "                    tmp.w * q.z + tmp.x * q.y - tmp.y * q.x + tmp.z * q.w,\n",
    "                    tmp.w * q.w - tmp.x * q.x - tmp.y * q.y - tmp.z * q.z)\n",
    "\n",
    "    def copy(self):\n",
    "        return quat(self.x, self.y, self.z, self.w)\n",
    "\n",
    "    '''\n",
    "    def inverse(self):\n",
    "        dot = quat_get_dot(self, self)\n",
    "        self.x = -self.x\n",
    "        self.y = -self.y\n",
    "        self.z = -self.z\n",
    "        self.mult_me(1 / dot)\n",
    "    '''\n",
    "\n",
    "    def round(self, d):\n",
    "        self.x = round(self.x, d)\n",
    "        self.y = round(self.y, d)\n",
    "        self.z = round(self.z, d)\n",
    "        self.w = round(self.w, d)\n",
    "\n",
    "    def round_(self, d):\n",
    "        return quat(round(self.x, d), round(self.y, d), round(self.z, d), round(self.w, d))\n",
    "\n",
    "    def inverse(self):\n",
    "        dot = quat_get_dot(self, self)\n",
    "        self.x = -self.x\n",
    "        self.y = -self.y\n",
    "        self.z = -self.z\n",
    "        self.x = self.x / dot\n",
    "        self.y = self.y / dot\n",
    "        self.z = self.z / dot\n",
    "        self.w = self.w / dot\n",
    "\n",
    "\n",
    "def quat_get_dot(self, t):\n",
    "    return self.x * t.x + self.y * t.y + self.z * t.z + self.w * t.w\n",
    "\n",
    "\n",
    "def get_dot_point(pt, t):\n",
    "    return pt.get_dot(t)\n",
    "\n",
    "\n",
    "def nomalize_point(pt):\n",
    "    return pt.normalize_me()\n",
    "\n",
    "\n",
    "def rotate_point(pt, pose):\n",
    "    return pt.get_rotated(pose['orient'])\n",
    "\n",
    "\n",
    "def transfer_point(pt, pose):\n",
    "    r_pt = pt.get_rotated(pose['orient'])\n",
    "    return r_pt.add_vector3(pose['position'])\n",
    "\n",
    "\n",
    "def move_point(pt, pose):\n",
    "    return pt.add_vector3(pose)\n",
    "\n",
    "\n",
    "def transfer_point_inverse(pt, pose):\n",
    "    t = copy.deepcopy(pose)\n",
    "    t['orient'].inverse()\n",
    "    r_pt = pt.sub_vector3(t['position'])\n",
    "    return r_pt.get_rotated(t['orient'])\n",
    "\n",
    "\n",
    "def get_quat_from_euler(order, value):\n",
    "    rt = R.from_euler(order, value, degrees=True)\n",
    "    return quat(rt.as_quat()[0], rt.as_quat()[1], rt.as_quat()[2], rt.as_quat()[3])\n",
    "\n",
    "\n",
    "def pose_apply(a, b):\n",
    "    return {'position': transfer_point(a['position'], b), 'orient': b['orient'].mult_quat(a['orient'])}\n",
    "\n",
    "\n",
    "def pose_apply_inverse(a, b):\n",
    "    t = copy.deepcopy(b)\n",
    "    t['orient'].inverse()\n",
    "    tmp = a['position'].sub_vector3(t['position'])\n",
    "    return {'position': tmp.get_rotated(t['orient']), 'orient': t['orient'].mult_quat(a['orient'])}\n",
    "\n",
    "\n",
    "def get_euler_from_quat(order, q):\n",
    "    rt = R.from_quat(np.array(q))\n",
    "    return rt.as_euler(order, degrees=True)\n",
    "\n",
    "\n",
    "def unit_vector(vector):\n",
    "    \"\"\"Returnstheunitvectorofthevector.\"\"\"\n",
    "    return vector / np.linalg.norm(vector)\n",
    "\n",
    "\n",
    "def angle_between(v1, v2):\n",
    "    \"\"\"Returnstheangleinradiansbetweenvectors'v1'and'v2'::\n",
    "    >>>angle_between((1,0,0),(0,1,0))\n",
    "    1.5707963267948966\n",
    "    >>>angle_between((1,0,0),(1,0,0))\n",
    "    0.0\n",
    "    >>>angle_between((1,0,0),(-1,0,0))\n",
    "    3.141592653589793\n",
    "    \"\"\"\n",
    "    v1_u = unit_vector(v1)\n",
    "    v2_u = unit_vector(v2)\n",
    "    return np.arccos(np.clip(np.dot(v1_u, v2_u), -1.0, 1.0))\n",
    "\n",
    "def rw_json_data(rw_mode, path, data):\n",
    "    try:\n",
    "        if rw_mode == READ:\n",
    "            with open(path, 'r', encoding=\"utf-8\") as rdata:\n",
    "                json_data = json.load(rdata)\n",
    "            return json_data\n",
    "        elif rw_mode == WRITE:\n",
    "            with open(path, 'w', encoding=\"utf-8\") as wdata:\n",
    "                json.dump(data, wdata, ensure_ascii=False, indent=\"\\t\")\n",
    "        else:\n",
    "            print('not support mode')\n",
    "    except:\n",
    "        print('exception')\n",
    "        return ERROR\n",
    "\n",
    "\n",
    "def rw_file_storage(rw_cmd, name, left_map, right_map):\n",
    "    if rw_cmd == WRITE:\n",
    "        print(\"WRITE parameters ......\")\n",
    "        cv_file = cv2.FileStorage(name, cv2.FILE_STORAGE_WRITE)\n",
    "        cv_file.write(\"Left_Stereo_Map_x\", left_map[0])\n",
    "        cv_file.write(\"Left_Stereo_Map_y\", left_map[1])\n",
    "        cv_file.write(\"Right_Stereo_Map_x\", right_map[0])\n",
    "        cv_file.write(\"Right_Stereo_Map_y\", right_map[1])\n",
    "        cv_file.release()\n",
    "    else:\n",
    "        print(\"READ parameters ......\")\n",
    "        try:\n",
    "            # FILE_STORAGE_READ\n",
    "            cv_file = cv2.FileStorage(name, cv2.FILE_STORAGE_READ)\n",
    "            # note we also have to specify the type to retrieve other wise we only get a\n",
    "            # FileNode object back instead of a matrix\n",
    "            left_map = (cv_file.getNode(\"Left_Stereo_Map_x\").mat(), cv_file.getNode(\"Left_Stereo_Map_y\").mat())\n",
    "            right_map = (cv_file.getNode(\"Right_Stereo_Map_x\").mat(), cv_file.getNode(\"Right_Stereo_Map_y\").mat())\n",
    "\n",
    "            cv_file.release()\n",
    "\n",
    "            return DONE, left_map, right_map\n",
    "        except:\n",
    "            traceback.print_exc()\n",
    "            return ERROR, NOT_SET, NOT_SET\n",
    "\n",
    "\n",
    "def Rotate(src, degrees):\n",
    "    if degrees == 90:\n",
    "        dst = cv2.transpose(src)\n",
    "        dst = cv2.flip(dst, 1)\n",
    "\n",
    "    elif degrees == 180:\n",
    "        dst = cv2.flip(src, -1)\n",
    "\n",
    "    elif degrees == 270:\n",
    "        dst = cv2.transpose(src)\n",
    "        dst = cv2.flip(dst, 0)\n",
    "    else:\n",
    "        dst = NOT_SET\n",
    "    return dst\n",
    "\n",
    "\n",
    "def terminal_cmd(cmd_m, cmd_s):\n",
    "    print('start ', terminal_cmd.__name__)\n",
    "    try:\n",
    "        result = subprocess.run([cmd_m, cmd_s], stdout=subprocess.PIPE).stdout.decode('utf-8')\n",
    "\n",
    "        device_re = re.compile(b\"Bus\\s+(?P<bus>\\d+)\\s+Device\\s+(?P<device>\\d+).+ID\\s(?P<id>\\w+:\\w+)\\s(?P<tag>.+)$\",\n",
    "                               re.I)\n",
    "        df = subprocess.check_output(\"lsusb\")\n",
    "        devices = []\n",
    "        for i in df.split(b'\\n'):\n",
    "            if i:\n",
    "                info = device_re.match(i)\n",
    "                if info:\n",
    "                    dinfo = info.groupdict()\n",
    "                    dinfo['device'] = '/dev/bus/usb/%s/%s' % (dinfo.pop('bus'), dinfo.pop('device'))\n",
    "                    devices.append(dinfo)\n",
    "    except:\n",
    "        print('exception')\n",
    "        traceback.print_exc()\n",
    "    else:\n",
    "        print('done')\n",
    "    finally:\n",
    "        if DEBUG == ENABLE:\n",
    "            print(devices)\n",
    "    temp = result.split('\\n\\n')\n",
    "    print(\"==================================================\")\n",
    "    ret_val = []\n",
    "    for i in range(len(temp)):\n",
    "        if SENSOR_NAME in temp[i]:\n",
    "            ret_val.append(temp[i])\n",
    "            print(\"add camera dev\", temp[i])\n",
    "        else:\n",
    "            print(\"skipping camera\", temp[i])\n",
    "    print(\"==================================================\")\n",
    "    return ret_val\n",
    "\n",
    "\n",
    "\n",
    "def init_data_array(cam_dev):\n",
    "    print(cam_dev_list)\n",
    "    camera_info_array = []\n",
    "    for i in range(len(cam_dev_list)):\n",
    "        cam_info = cam_dev_list[i].split('\\n\\t')\n",
    "        for cam_id, dev_name in enumerate(cam_info):\n",
    "            if 'dev' in dev_name:\n",
    "                # print(dev_name)\n",
    "                camera_info_array.append({'idx': cam_id,\n",
    "                            'port': dev_name,\n",
    "                            'display': {'width': CAP_PROP_FRAME_WIDTH, 'height': CAP_PROP_FRAME_HEIGHT},\n",
    "\n",
    "                            'blobs': [],\n",
    "                            'med_blobs': [],\n",
    "\n",
    "                            'distorted_2d': [],\n",
    "                            'undistorted_2d': [],\n",
    "\n",
    "                            'cam_cal': {'cameraK': cameraK, 'dist_coeff': distCoeff},\n",
    "\n",
    "                            'detect_status': [NOT_SET, 0, 0],\n",
    "\n",
    "                            'track_cal': {'data': [], 'recording': {'name': NOT_SET}},\n",
    "\n",
    "                            'D_R_T': {'rvecs': NOT_SET, 'tvecs': NOT_SET},\n",
    "                            'D_R_T_A': [],\n",
    "                            'RER': {'C_R_T': {'rvecs': NOT_SET, 'tvecs': NOT_SET}}})\n",
    "\n",
    "    \n",
    "    print('camera info', camera_info_array)\n",
    "\n",
    "    return camera_info_array\n",
    "\n",
    "\n",
    "def init_coord_json(file):\n",
    "    print('start ', init_coord_json.__name__)\n",
    "    try:\n",
    "        json_file = open(''.join(['jsons/specs/', f'{file}']))\n",
    "        jsonObject = json.load(json_file)\n",
    "        model_points = jsonObject.get('TrackedObject').get('ModelPoints')\n",
    "        pts = [0 for i in range(len(model_points))]\n",
    "        for data in model_points:\n",
    "            idx = data.split('Point')[1]\n",
    "            x = model_points.get(data)[0]\n",
    "            y = model_points.get(data)[1]\n",
    "            z = model_points.get(data)[2]\n",
    "            u = model_points.get(data)[3]\n",
    "            v = model_points.get(data)[4]\n",
    "            w = model_points.get(data)[5]\n",
    "            r1 = model_points.get(data)[6]\n",
    "            r2 = model_points.get(data)[7]\n",
    "            r3 = model_points.get(data)[8]\n",
    "            pts[int(idx)] = {'idx': idx,\n",
    "                             'pos': [x, y, z],\n",
    "                             'dir': [u, v, w],\n",
    "                             'res': [r1, r2, r3],\n",
    "                             'pair_xy': [],\n",
    "                             'remake_3d': []}\n",
    "\n",
    "            print(''.join(['{ .pos = {{', f'{x}', ',', f'{y}', ',', f'{z}',\n",
    "                           ' }}, .dir={{', f'{u}', ',', f'{v}', ',', f'{w}', ' }}, .pattern=', f'{idx}', '},']))\n",
    "    except:\n",
    "        print('exception')\n",
    "        traceback.print_exc()\n",
    "    finally:\n",
    "        print('done')\n",
    "    return pts\n",
    "\n",
    "def view_camera_infos(frame, text, x, y):\n",
    "    cv2.putText(frame, text,\n",
    "                (x, y),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), lineType=cv2.LINE_AA)\n",
    "\n",
    "def find_center(frame, led_num, X, Y, W, H, blobs):\n",
    "    x_sum = 0\n",
    "    t_sum = 0\n",
    "    y_sum = 0\n",
    "    m_count = 0\n",
    "    g_c_x = 0\n",
    "    g_c_y = 0\n",
    "\n",
    "    ret_blobs = copy.deepcopy(blobs)\n",
    "\n",
    "    for y in range(Y, Y + H):\n",
    "        for x in range(X, X + W):\n",
    "            if frame[y][x] >= CV_MID_THRESHOLD:\n",
    "                x_sum += x * frame[y][x]\n",
    "                t_sum += frame[y][x]\n",
    "                m_count += 1\n",
    "\n",
    "    for x in range(X, X + W):\n",
    "        for y in range(Y, Y + H):\n",
    "            if frame[y][x] >= CV_MID_THRESHOLD:\n",
    "                y_sum += y * frame[y][x]\n",
    "\n",
    "    if t_sum != 0:\n",
    "        g_c_x = x_sum / t_sum\n",
    "        g_c_y = y_sum / t_sum\n",
    "\n",
    "    # print('led ', led_num, ' x ', g_c_x, ' y ', g_c_y)\n",
    "\n",
    "    if g_c_x == 0 or g_c_y == 0:\n",
    "        return ERROR\n",
    "\n",
    "    if len(ret_blobs) > 0:\n",
    "        detect = 0\n",
    "        for i, datas in enumerate(ret_blobs):\n",
    "            led = datas['idx']\n",
    "            if led == led_num:\n",
    "                ret_blobs[i] = {'idx': led_num, 'cx': g_c_x, 'cy': g_c_y}\n",
    "                detect = 1\n",
    "                break\n",
    "        if detect == 0:\n",
    "            ret_blobs.append({'idx': led_num, 'cx': g_c_x, 'cy': g_c_y})\n",
    "    else:\n",
    "        ret_blobs.append({'idx': led_num, 'cx': g_c_x, 'cy': g_c_y})\n",
    "\n",
    "    return DONE, ret_blobs\n",
    "\n",
    "\n",
    "def simple_solvePNP(cam_id, frame, blob_array):\n",
    "    model_points = []\n",
    "    image_points = []\n",
    "    led_ids = []\n",
    "    interationsCount = 100\n",
    "    confidence = 0.99\n",
    "\n",
    "    for blobs in blob_array:\n",
    "        led_num = int(blobs['idx'])\n",
    "        # if DEBUG == ENABLE:\n",
    "        #     print('idx:', led_num, ' added 3d', leds_dic['pts'][led_num]['pos'], ' remake: ',\n",
    "        #           leds_dic['target_pts'][led_num]['remake_3d'],\n",
    "        #           ' 2d', [blobs['cx'], blobs['cy']])\n",
    "\n",
    "        model_points.append(leds_dic['pts'][led_num]['pos'])\n",
    "        led_ids.append(led_num)\n",
    "        image_points.append([blobs['cx'], blobs['cy']])\n",
    "\n",
    "    model_points_len = len(model_points)\n",
    "    image_points_len = len(image_points)\n",
    "\n",
    "    # check assertion\n",
    "    if model_points_len != image_points_len:\n",
    "        print(\"assertion len is not equal\")\n",
    "        return ERROR\n",
    "\n",
    "    if model_points_len < 4 or image_points_len < 4:\n",
    "        print(\"assertion < 4: \")\n",
    "        return ERROR\n",
    "\n",
    "    camera_k = leds_dic['cam_info'][cam_id]['cam_cal']['cameraK']\n",
    "    dist_coeff = leds_dic['cam_info'][cam_id]['cam_cal']['dist_coeff']\n",
    "\n",
    "    list_2d_distorted = np.zeros((image_points_len, 1, 2), dtype=np.float64)\n",
    "    for i in range(image_points_len):\n",
    "        list_2d_distorted[i] = image_points[i]\n",
    "\n",
    "    points3D = np.array(model_points)\n",
    "\n",
    "    list_2d_undistorted = cv2.fisheye.undistortPoints(list_2d_distorted, camera_k, dist_coeff)\n",
    "    leds_dic['cam_info'][cam_id]['distorted_2d'] = copy.deepcopy(list_2d_distorted)\n",
    "    leds_dic['cam_info'][cam_id]['undistorted_2d'] = copy.deepcopy(list_2d_undistorted)\n",
    "\n",
    "    if DO_UNDISTORT == ENABLE:\n",
    "        temp_points2D = []\n",
    "        for u_data in list_2d_undistorted:\n",
    "            temp_points2D.append([u_data[0][0], u_data[0][1]])\n",
    "        points2D = np.array(temp_points2D)\n",
    "        temp_camera_k = cameraK\n",
    "        temp_dist_coeff = distCoeff\n",
    "    else:\n",
    "        points2D = np.array(image_points)\n",
    "        temp_camera_k = leds_dic['cam_info'][cam_id]['cam_cal']['cameraK']\n",
    "        temp_dist_coeff = leds_dic['cam_info'][cam_id]['cam_cal']['dist_coeff']\n",
    "\n",
    "    if DO_SOLVEPNP_RANSAC == ENABLE:\n",
    "        success, rvecs, tvecs, inliers = cv2.solvePnPRansac(points3D, points2D,\n",
    "                                                            temp_camera_k,\n",
    "                                                            temp_dist_coeff,\n",
    "                                                            useExtrinsicGuess=True,\n",
    "                                                            iterationsCount=interationsCount,\n",
    "                                                            confidence=confidence,\n",
    "                                                            reprojectionError=1.0,\n",
    "                                                            flags=cv2.SOLVEPNP_ITERATIVE)\n",
    "\n",
    "    else:\n",
    "        success, rvecs, tvecs = cv2.solvePnP(points3D, points2D,\n",
    "                                             temp_camera_k,\n",
    "                                             temp_dist_coeff,\n",
    "                                             flags=cv2.SOLVEPNP_AP3P)\n",
    "        # length = len(points2D)\n",
    "        # for i in range(length):\n",
    "        #     inliers = np.array(\n",
    "        #         [i for i in range(length)]).reshape(\n",
    "        #         length, 1)\n",
    "\n",
    "    # ret, RER, TRER, candidate_array, except_inlier = cal_RER_px(led_ids, frame,\n",
    "    #                                                             points3D, points2D,\n",
    "    #                                                             inliers,\n",
    "    #                                                             rvecs,\n",
    "    #                                                             tvecs,\n",
    "    #                                                             temp_camera_k,\n",
    "    #                                                             temp_dist_coeff, DONE)\n",
    "\n",
    "    # if ret == SUCCESS:\n",
    "    #     #####\n",
    "    #     leds_dic['cam_info'][cam_id]['D_R_T_A'].append({'rvecs': rvecs, 'tvecs': tvecs})\n",
    "    #     #####\n",
    "    #     leds_dic['cam_info'][cam_id]['RER']['C_R_T'] = {'rvecs': rvecs, 'tvecs': tvecs}\n",
    "    #     return SUCCESS, candidate_array\n",
    "    # else:\n",
    "    #     return ERROR, candidate_array\n",
    "\n",
    "    leds_dic['cam_info'][cam_id]['D_R_T_A'].append({'rvecs': rvecs, 'tvecs': tvecs})\n",
    "    #####\n",
    "    leds_dic['cam_info'][cam_id]['RER']['C_R_T'] = {'rvecs': rvecs, 'tvecs': tvecs}\n",
    "    return SUCCESS, blob_array\n",
    "\n",
    "\n",
    "def cal_RER_px(led_ids, frame, points3D, points2D, inliers, rvecs, tvecs, camera_k, dist_coeff, status):\n",
    "    # Compute re-projection error.\n",
    "    blob_array = []\n",
    "    points2D_reproj = cv2.projectPoints(points3D, rvecs,\n",
    "                                        tvecs, camera_k, dist_coeff)[0].squeeze(1)\n",
    "    # print('points2D_reproj\\n', points2D_reproj, '\\npoints2D\\n', points2D, '\\n inliers: ', inliers)\n",
    "    assert (points2D_reproj.shape == points2D.shape)\n",
    "    error = (points2D_reproj - points2D)[inliers]  # Compute error only over inliers.\n",
    "    # print('error', error)\n",
    "    rmse = 0.0\n",
    "    dis = 0.0\n",
    "    led_except = -1\n",
    "    except_inlier = -1\n",
    "    led_dis = []\n",
    "\n",
    "    for idx, error_data in enumerate(error[:, 0]):\n",
    "        rmse += np.power(error_data[0], 2) + np.power(error_data[1], 2)\n",
    "        temp_dis = np.power(error_data[0], 2) + np.power(error_data[1], 2)\n",
    "        led_dis.append(temp_dis)\n",
    "\n",
    "        if status == NOT_SET:\n",
    "            if temp_dis > dis:\n",
    "                dis = temp_dis\n",
    "                led_except = led_ids[idx]\n",
    "                except_inlier = idx\n",
    "\n",
    "        # print('led_num: ', led_ids[idx], ' dis:', '%0.18f' % temp_dis, ' : ',\n",
    "        #       points2D_reproj[idx][0], ' ', points2D_reproj[idx][1],\n",
    "        #       ' vs ', points2D[idx][0], ' ', points2D[idx][1])\n",
    "\n",
    "        if temp_dis > 100:\n",
    "            return ERROR, 0, 0, blob_array, except_inlier\n",
    "\n",
    "    trmse = float(rmse - dis)\n",
    "    # print('trmse : ', trmse, ' rmse : ', rmse)\n",
    "    if inliers is None:\n",
    "        return ERROR, -1, -1, blob_array, except_inlier\n",
    "    RER = round(np.sqrt(rmse) / len(inliers), 18)\n",
    "    if status == NOT_SET:\n",
    "        TRER = round(np.sqrt(trmse) / (len(inliers) - 1), 18)\n",
    "        if led_except == -1:\n",
    "            return ERROR, RER, TRER, blob_array, except_inlier\n",
    "    else:\n",
    "        TRER = round(np.sqrt(trmse) / (len(inliers)), 18)\n",
    "\n",
    "    for i, idx in enumerate(led_ids):\n",
    "        if idx != led_except:\n",
    "            blob_array.append({'idx': led_ids[i],\n",
    "                               'cx': points2D[i][0], 'cy': points2D[i][1], 'area': 0})\n",
    "\n",
    "    return SUCCESS, RER, TRER, blob_array, except_inlier\n",
    "\n",
    "\n",
    "def cal_iqr_func(arr):\n",
    "    Q1 = np.percentile(arr, 25)\n",
    "    Q3 = np.percentile(arr, 75)\n",
    "\n",
    "    IQR = Q3 - Q1\n",
    "\n",
    "    outlier_step = 1.5 * IQR\n",
    "\n",
    "    lower_bound = Q1 - outlier_step\n",
    "    upper_bound = Q3 + outlier_step\n",
    "\n",
    "    mask = np.where((arr > upper_bound) | (arr < lower_bound))\n",
    "\n",
    "    # print(f\"cal_iqr_func!!!!!! lower_bound = {lower_bound} upper_bound ={upper_bound} mask = {mask}\")\n",
    "\n",
    "    return mask\n",
    "\n",
    "\n",
    "def detect_outliers(idx, blob_array, remove_index_array):\n",
    "    temp_x = np.array(cal_iqr_func(blob_array[0]))\n",
    "    temp_y = np.array(cal_iqr_func(blob_array[1]))\n",
    "\n",
    "    for x in temp_x:\n",
    "        for xx in x:\n",
    "            if xx in remove_index_array:\n",
    "                continue\n",
    "            else:\n",
    "                remove_index_array.append(xx)\n",
    "    for y in temp_y:\n",
    "        for yy in y:\n",
    "            if yy in remove_index_array:\n",
    "                continue\n",
    "            else:\n",
    "                remove_index_array.append(yy)\n",
    "\n",
    "    remove_index_array.sort()\n",
    "\n",
    "    # print(\"detect_outliers!!!!!!!!!!!!!!!!!!!!!!!!!!!! remove_index_array\", remove_index_array)\n",
    "\n",
    "\n",
    "def median_blobs(cam_id, blob_array, rt_array):\n",
    "    blob_cnt = len(blob_array)\n",
    "    if blob_cnt == 0:\n",
    "        print('blob_cnt is 0')\n",
    "        return ERROR\n",
    "    blob_length = len(blob_array[0])\n",
    "\n",
    "    med_blobs_array = []\n",
    "    remove_index_array = []\n",
    "    med_rt_array = []\n",
    "    print('cam_id:', cam_id, ' blob_cnt:', blob_cnt)\n",
    "\n",
    "    for i in range(blob_length):\n",
    "        med_xy = [[], [], []]\n",
    "        for ii in range(blob_cnt):\n",
    "            med_xy[0].append(blob_array[ii][i]['cx'])\n",
    "            med_xy[1].append(blob_array[ii][i]['cy'])\n",
    "            # med_xy[2].append(blob_array[ii][i]['area'])\n",
    "        detect_outliers(blob_array[ii][i]['idx'], med_xy, remove_index_array)\n",
    "\n",
    "    r_len = len(remove_index_array)\n",
    "    print(f\"median_blobs!!!!! remove_index_array length={r_len}\")\n",
    "\n",
    "    for i in range(blob_length):\n",
    "        med_xy = [[], [], []]\n",
    "        for ii in range(blob_cnt):\n",
    "            med_xy[0].append(blob_array[ii][i]['cx'])\n",
    "            med_xy[1].append(blob_array[ii][i]['cy'])\n",
    "            # med_xy[2].append(blob_array[ii][i]['area'])\n",
    "        # tempx=med_xy[0]\n",
    "        # print(f\"original med_xy[0] = {tempx}\")\n",
    "        count = 0\n",
    "        for index in remove_index_array:\n",
    "            med_xy[0].pop(index - count)\n",
    "            med_xy[1].pop(index - count)\n",
    "            # med_xy[2].pop(index - count)\n",
    "            count += 1\n",
    "        # tempx=med_xy[0]\n",
    "        # print(f\"after pop med_xy[0] = {tempx}\")\n",
    "\n",
    "        mean_med_x = np.mean(med_xy[0])\n",
    "        mean_med_y = np.mean(med_xy[1])\n",
    "\n",
    "        med_blobs_array.append({'idx': blob_array[ii][i]['idx'],\n",
    "                                'cx': mean_med_x,\n",
    "                                'cy': mean_med_y})\n",
    "\n",
    "    if rt_array != NOT_SET:\n",
    "        count = 0\n",
    "        for index in remove_index_array:\n",
    "            rt_array.pop(index - count)\n",
    "            count += 1\n",
    "        for i in range(len(rt_array)):\n",
    "            rvt = [[], [], []]\n",
    "            for x in rt_array[i]['rvecs'][0]:\n",
    "                rvt[0].append(x)\n",
    "            for y in rt_array[i]['rvecs'][1]:\n",
    "                rvt[1].append(y)\n",
    "            for z in rt_array[i]['rvecs'][2]:\n",
    "                rvt[2].append(z)\n",
    "            tvt = [[], [], []]\n",
    "            for x in rt_array[i]['tvecs'][0]:\n",
    "                tvt[0].append(x)\n",
    "            for y in rt_array[i]['tvecs'][1]:\n",
    "                tvt[1].append(y)\n",
    "            for z in rt_array[i]['tvecs'][2]:\n",
    "                tvt[2].append(z)\n",
    "\n",
    "        mean_rvt = []\n",
    "        mean_tvt = []\n",
    "        for i in range(0, 3):\n",
    "            mean_rvt.append(np.mean(rvt[i]))\n",
    "            mean_tvt.append(np.mean(tvt[i]))\n",
    "\n",
    "        med_rt_array = {'rvecs': np.array([[mean_rvt[0]], [mean_rvt[1]], [mean_rvt[2]]], dtype=np.float64),\n",
    "                        'tvecs': np.array([[mean_tvt[0]], [mean_tvt[1]], [mean_tvt[2]]], dtype=np.float64)}\n",
    "\n",
    "        len_rt_array = len(rt_array)\n",
    "    #     print(f\"rt_array_len = {len_rt_array}\")\n",
    "    #     print(f\"med_rt_array = {med_rt_array}\")\n",
    "    # print(f\"med_blobs_array = {med_blobs_array}\")\n",
    "\n",
    "    blob_array = med_blobs_array\n",
    "\n",
    "    return blob_array, med_rt_array\n",
    "\n",
    "\n",
    "leds_dic = {}\n",
    "\n",
    "# Default\n",
    "CAP_PROP_FRAME_WIDTH = 1920\n",
    "CAP_PROP_FRAME_HEIGHT = 1080\n",
    "\n",
    "# Defining the dimensions of checkerboard\n",
    "CHECKERBOARD = (7, 4)\n",
    "# Termination criteria for refining the detected corners\n",
    "CRITERIA = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
    "cameraK = np.eye(3).astype(np.float64)\n",
    "distCoeff = np.zeros((4, 1)).astype(np.float64)\n",
    "\n",
    "ENABLE = 1\n",
    "DISABLE = 0\n",
    "\n",
    "DONE = 'DONE'\n",
    "NOT_SET = 'NOT_SET'\n",
    "\n",
    "READ = 0\n",
    "WRITE = 1\n",
    "\n",
    "ERROR = -1\n",
    "SUCCESS = 1\n",
    "\n",
    "DEBUG = ENABLE\n",
    "\n",
    "SENSOR_NAME = \"Droidcam\"\n",
    "\n",
    "EXTERNAL_TOOL_CALIBRATION = 'calibration_json'\n",
    "RECTIFY_MAP = \"improved_params2.xml\"\n",
    "CAM_DELAY = 1\n",
    "USE_EXTERNAL_TOOL_CALIBRAION = DISABLE\n",
    "RER_MAX = 100\n",
    "\n",
    "DO_ESTIMATE_POSE = ENABLE\n",
    "DO_SOLVEPNP_REFINE = DISABLE\n",
    "DO_UNDISTORT = DISABLE\n",
    "DO_SOLVEPNP_RANSAC = ENABLE\n",
    "USE_PRINT_FRAME = DISABLE\n",
    "PRINT_FRAME_INFOS = DISABLE\n",
    "RT_TEST = ENABLE\n",
    "\n",
    "ORIGIN = 'rifts2_left.json'\n",
    "JSON_FILE = 'stereo_json'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rangkast.jeong/Project/OpenCV_APP/API_TEST\n",
      "/usr/lib/python38.zip\n",
      "/usr/lib/python3.8\n",
      "/usr/lib/python3.8/lib-dynload\n",
      "\n",
      "/home/rangkast.jeong/.local/lib/python3.8/site-packages\n",
      "/usr/local/lib/python3.8/dist-packages\n",
      "/usr/local/lib/python3.8/dist-packages/PyBluez-0.23-py3.8-linux-x86_64.egg\n",
      "/usr/lib/python3/dist-packages\n",
      "start  terminal_cmd\n",
      "done\n",
      "[{'id': b'8087:8000', 'tag': b'Intel Corp. ', 'device': \"/dev/bus/usb/b'002'/b'002'\"}, {'id': b'1d6b:0002', 'tag': b'Linux Foundation 2.0 root hub', 'device': \"/dev/bus/usb/b'002'/b'001'\"}, {'id': b'8087:8008', 'tag': b'Intel Corp. ', 'device': \"/dev/bus/usb/b'001'/b'002'\"}, {'id': b'1d6b:0002', 'tag': b'Linux Foundation 2.0 root hub', 'device': \"/dev/bus/usb/b'001'/b'001'\"}, {'id': b'2833:0211', 'tag': b' ', 'device': \"/dev/bus/usb/b'004'/b'004'\"}, {'id': b'2833:0211', 'tag': b' ', 'device': \"/dev/bus/usb/b'004'/b'003'\"}, {'id': b'2109:0820', 'tag': b'VIA Labs, Inc. USB3.1 Hub             ', 'device': \"/dev/bus/usb/b'004'/b'002'\"}, {'id': b'1d6b:0003', 'tag': b'Linux Foundation 3.0 root hub', 'device': \"/dev/bus/usb/b'004'/b'001'\"}, {'id': b'1004:631d', 'tag': b'LG Electronics, Inc. Optimus Android Phone (Camera/PTP Mode)', 'device': \"/dev/bus/usb/b'003'/b'009'\"}, {'id': b'1004:631d', 'tag': b'LG Electronics, Inc. Optimus Android Phone (Camera/PTP Mode)', 'device': \"/dev/bus/usb/b'003'/b'010'\"}, {'id': b'2109:2820', 'tag': b'VIA Labs, Inc. USB2.0 Hub             ', 'device': \"/dev/bus/usb/b'003'/b'004'\"}, {'id': b'8087:07da', 'tag': b'Intel Corp. ', 'device': \"/dev/bus/usb/b'003'/b'003'\"}, {'id': b'0853:0134', 'tag': b'Topre Corporation Mini Keyboard', 'device': \"/dev/bus/usb/b'003'/b'005'\"}, {'id': b'046d:c52f', 'tag': b'Logitech, Inc. Unifying Receiver', 'device': \"/dev/bus/usb/b'003'/b'002'\"}, {'id': b'1d6b:0002', 'tag': b'Linux Foundation 2.0 root hub', 'device': \"/dev/bus/usb/b'003'/b'001'\"}]\n",
      "==================================================\n",
      "add camera dev Droidcam (platform:v4l2loopback_dc-000):\n",
      "\t/dev/video0\n",
      "\t/dev/video1\n",
      "skipping camera Rift Sensor: CV1 External Camer (usb-0000:00:14.0-5.1):\n",
      "\t/dev/video2\n",
      "\t/dev/video3\n",
      "\t/dev/media0\n",
      "skipping camera Rift Sensor: CV1 External Camer (usb-0000:00:14.0-5.2):\n",
      "\t/dev/video4\n",
      "\t/dev/video5\n",
      "\t/dev/media1\n",
      "skipping camera \n",
      "==================================================\n",
      "['Droidcam (platform:v4l2loopback_dc-000):\\n\\t/dev/video0\\n\\t/dev/video1']\n",
      "camera info [{'idx': 1, 'port': '/dev/video0', 'display': {'width': 1920, 'height': 1080}, 'blobs': [], 'med_blobs': [], 'distorted_2d': [], 'undistorted_2d': [], 'cam_cal': {'cameraK': array([[1., 0., 0.],\n",
      "       [0., 1., 0.],\n",
      "       [0., 0., 1.]]), 'dist_coeff': array([[0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.]])}, 'detect_status': ['NOT_SET', 0, 0], 'track_cal': {'data': [], 'recording': {'name': 'NOT_SET'}}, 'D_R_T': {'rvecs': 'NOT_SET', 'tvecs': 'NOT_SET'}, 'D_R_T_A': [], 'RER': {'C_R_T': {'rvecs': 'NOT_SET', 'tvecs': 'NOT_SET'}}}, {'idx': 2, 'port': '/dev/video1', 'display': {'width': 1920, 'height': 1080}, 'blobs': [], 'med_blobs': [], 'distorted_2d': [], 'undistorted_2d': [], 'cam_cal': {'cameraK': array([[1., 0., 0.],\n",
      "       [0., 1., 0.],\n",
      "       [0., 0., 1.]]), 'dist_coeff': array([[0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.]])}, 'detect_status': ['NOT_SET', 0, 0], 'track_cal': {'data': [], 'recording': {'name': 'NOT_SET'}}, 'D_R_T': {'rvecs': 'NOT_SET', 'tvecs': 'NOT_SET'}, 'D_R_T_A': [], 'RER': {'C_R_T': {'rvecs': 'NOT_SET', 'tvecs': 'NOT_SET'}}}]\n",
      "start  init_coord_json\n",
      "{ .pos = {{0.03300807,0.00371497,0.00026865 }}, .dir={{0.7051038,-0.6950803,0.14032818 }}, .pattern=12},\n",
      "{ .pos = {{0.04222733,0.0228845,-0.00394005 }}, .dir={{0.9435189,-0.10477919,-0.31431419 }}, .pattern=11},\n",
      "{ .pos = {{0.02000199,-0.00388647,-0.014973 }}, .dir={{0.49720891,-0.70839529,-0.5009585 }}, .pattern=14},\n",
      "{ .pos = {{0.03006234,0.00378822,-0.01297127 }}, .dir={{0.67315478,-0.5810967,-0.45737213 }}, .pattern=13},\n",
      "{ .pos = {{0.04265723,0.03016438,0.01624689 }}, .dir={{0.90904575,-0.17393345,0.37865945 }}, .pattern=10},\n",
      "{ .pos = {{-0.02146761,-0.00343424,-0.01381839 }}, .dir={{-0.52706841,-0.71386452,-0.46108171 }}, .pattern=0},\n",
      "{ .pos = {{-0.0318701,0.00568587,-0.01206734 }}, .dir={{-0.71941994,-0.53832866,-0.43890456 }}, .pattern=1},\n",
      "{ .pos = {{-0.03692925,0.00930785,0.00321071 }}, .dir={{-0.75763735,-0.6234486,0.19312559 }}, .pattern=2},\n",
      "{ .pos = {{-0.04287211,0.02691347,-0.00194137 }}, .dir={{-0.95565641,0.00827838,-0.29436762 }}, .pattern=3},\n",
      "{ .pos = {{-0.04170018,0.03609551,0.01989264 }}, .dir={{-0.89943476,-0.04857372,0.43434745 }}, .pattern=4},\n",
      "{ .pos = {{-0.02923584,0.06186962,0.0161972 }}, .dir={{-0.57938915,0.80424722,-0.13226727 }}, .pattern=5},\n",
      "{ .pos = {{-0.01456789,0.06295633,0.03659283 }}, .dir={{-0.32401356,0.5869508,0.74195955 }}, .pattern=6},\n",
      "{ .pos = {{0.00766914,0.07115411,0.0206431 }}, .dir={{0.14082806,0.97575588,-0.16753482 }}, .pattern=7},\n",
      "{ .pos = {{0.02992447,0.05507271,0.03108736 }}, .dir={{0.66436362,0.41503629,0.62158335 }}, .pattern=8},\n",
      "{ .pos = {{0.03724313,0.05268665,0.01100446 }}, .dir={{0.77126662,0.61174447,-0.17583089 }}, .pattern=9},\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "# init camera data array\n",
    "import sys\n",
    "for p in sys.path:\n",
    "    print(p)\n",
    "cam_dev_list = terminal_cmd('v4l2-ctl', '--list-devices')\n",
    "leds_dic['cam_info'] = init_data_array(cam_dev_list)\n",
    "leds_dic['pts'] = init_coord_json(ORIGIN)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cap1 size: 1736, 2312\n",
      "cap2 size: 1736, 2312\n"
     ]
    }
   ],
   "source": [
    "# camera setting test\n",
    "cap1_name = leds_dic['cam_info'][0]['port']\n",
    "cap1 = cv2.VideoCapture(cap1_name)\n",
    "cap2_name = leds_dic['cam_info'][1]['port']\n",
    "cap2 = cv2.VideoCapture(cap2_name)\n",
    "\n",
    "width1 = cap1.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
    "height1 = cap1.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
    "print('cap1 size: %d, %d' % (width1, height1))\n",
    "leds_dic['cam_info'][0]['display']['width'] = width1\n",
    "leds_dic['cam_info'][0]['display']['height'] = height1\n",
    "\n",
    "\n",
    "width2 = cap2.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
    "height2 = cap2.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
    "print('cap2 size: %d, %d' % (width2, height2))\n",
    "leds_dic['cam_info'][1]['display']['width'] = width2\n",
    "leds_dic['cam_info'][1]['display']['height'] = height2\n",
    "\n",
    "if not cap1.isOpened() or not cap2.isOpened():\n",
    "    sys.exit()\n",
    "\n",
    "while True:\n",
    "    ret1, frame1 = cap1.read()\n",
    "    ret2, frame2 = cap2.read()\n",
    "    if not ret1 or not ret2:\n",
    "        break\n",
    "    if cv2.waitKey(1) & 0xFF == 27:  # Esc pressed\n",
    "        break\n",
    "    imgL = Rotate(frame1, 270)\n",
    "    imgR = Rotate(frame2, 270)\n",
    "    view_camera_infos(imgL, f'{cap1_name}', 30, 35)\n",
    "    cv2.circle(imgL, (int(height1 / 2), int(width1 / 2)), 3, color=(0, 0, 255),\n",
    "                thickness=-1)\n",
    "    cv2.imshow('left camera', imgL)\n",
    "    view_camera_infos(imgR, f'{cap2_name}', 30, 35)\n",
    "    cv2.circle(imgR, (int(height2 / 2), int(width2 / 2)), 3, color=(0, 0, 255),\n",
    "                thickness=-1)\n",
    "    cv2.imshow(\"right camera\", imgR)\n",
    "\n",
    "    cv2.waitKey(CAM_DELAY)\n",
    "\n",
    "cap1.release()\n",
    "cap2.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "try to open: /dev/video0\n",
      "width  1736.0\n",
      "height  2312.0\n",
      "Select a ROI and then press SPACE or ENTER button!\n",
      "Cancel the selection process by pressing c button!\n",
      "Press q to quit selecting boxes and start tracking\n",
      "Press any other key to select next object\n",
      "led num  0\n",
      "Select a ROI and then press SPACE or ENTER button!\n",
      "Cancel the selection process by pressing c button!\n",
      "Press q to quit selecting boxes and start tracking\n",
      "Press any other key to select next object\n",
      "led num  1\n",
      "Select a ROI and then press SPACE or ENTER button!\n",
      "Cancel the selection process by pressing c button!\n",
      "Press q to quit selecting boxes and start tracking\n",
      "Press any other key to select next object\n",
      "led num  2\n",
      "Select a ROI and then press SPACE or ENTER button!\n",
      "Cancel the selection process by pressing c button!\n",
      "Press q to quit selecting boxes and start tracking\n",
      "Press any other key to select next object\n",
      "led num  3\n",
      "Selected bounding boxes [{'idx': 0, 'bbox': (1467, 834, 30, 33)}, {'idx': 1, 'bbox': (1408, 844, 38, 43)}, {'idx': 2, 'bbox': (1351, 792, 42, 41)}, {'idx': 3, 'bbox': (1274, 852, 39, 35)}]\n",
      "try to open: /dev/video1\n",
      "width  1736.0\n",
      "height  2312.0\n",
      "Selected bounding boxes []\n"
     ]
    }
   ],
   "source": [
    "# multi tracker test (PHONE)\n",
    "import time\n",
    "from datetime import datetime, date, time, timedelta\n",
    "\n",
    "trackerTypes = ['BOOSTING', 'MIL', 'KCF', 'TLD', 'MEDIANFLOW', 'GOTURN', 'MOSSE', 'CSRT']\n",
    "def createTrackerByName(trackerType):\n",
    "    # Create a tracker based on tracker name\n",
    "    if trackerType == trackerTypes[0]:\n",
    "        tracker = cv2.legacy.TrackerBoosting_create()\n",
    "    elif trackerType == trackerTypes[1]:\n",
    "        tracker = cv2.legacy.TrackerMIL_create()\n",
    "    elif trackerType == trackerTypes[2]:\n",
    "        tracker = cv2.legacy.TrackerKCF_create()\n",
    "    elif trackerType == trackerTypes[3]:\n",
    "        tracker = cv2.legacy.TrackerTLD_create()\n",
    "    elif trackerType == trackerTypes[4]:\n",
    "        tracker = cv2.legacy.TrackerMedianFlow_create()\n",
    "    elif trackerType == trackerTypes[5]:\n",
    "        tracker = cv2.legacy.TrackerGOTURN_create()\n",
    "    elif trackerType == trackerTypes[6]:\n",
    "        tracker = cv2.TrackerMOSSE_create()\n",
    "    elif trackerType == trackerTypes[7]:\n",
    "        tracker = cv2.legacy.TrackerCSRT_create()\n",
    "    else:\n",
    "        tracker = None\n",
    "        print('Incorrect tracker name')\n",
    "        print('Available trackers are:')\n",
    "        for t in trackerTypes:\n",
    "            print(t)\n",
    "\n",
    "    return tracker\n",
    "\n",
    "\n",
    "## Select boxes\n",
    "CV_FINDCONTOUR_LVL = 140\n",
    "CV_THRESHOLD = 170\n",
    "CV_MIN_THRESHOLD = 170\n",
    "CV_MID_THRESHOLD = 190\n",
    "CV_MAX_THRESHOLD = 255\n",
    "bboxes = []\n",
    "blobs = []\n",
    "\n",
    "for cam_id in range(len(leds_dic['cam_info'])):\n",
    "    print('try to open:', leds_dic['cam_info'][cam_id]['port'])\n",
    "    video_src = leds_dic['cam_info'][cam_id]['port']\n",
    "\n",
    "    width = int(leds_dic['cam_info'][cam_id]['display']['width'])\n",
    "    height = int(leds_dic['cam_info'][cam_id]['display']['height'])\n",
    "\n",
    "    cap = cv2.VideoCapture(video_src)    \n",
    "    cap.set(cv2.CAP_PROP_FRAME_WIDTH, width)\n",
    "    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, height)\n",
    "\n",
    "\n",
    "    print('width ' , leds_dic['cam_info'][cam_id]['display']['width'])\n",
    "    print('height ' , leds_dic['cam_info'][cam_id]['display']['height'])\n",
    "\n",
    "    # cap.set(cv2.CAP_PROP_FORMAT, cv2.CV_64FC1)\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print('Cannot read video file')\n",
    "            break\n",
    "        # frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        frame = Rotate(frame, 270)\n",
    "        img_draw = frame.copy()\n",
    "\n",
    "        if cv2.waitKey(1) == ord('a'):\n",
    "            view_camera_infos(frame, 'drag led area and press space bar',\n",
    "                                30, 35)\n",
    "            cv2.imshow('MultiTracker', frame)\n",
    "            bbox = cv2.selectROI('MultiTracker', frame)\n",
    "            print(\"Press q to quit selecting boxes and start tracking\")\n",
    "            print(\"Press any other key to select next object\")\n",
    "            view_camera_infos(frame, 'press led numer',\n",
    "                                30, 70)\n",
    "            cv2.imshow('MultiTracker', frame)\n",
    "            while True:\n",
    "                # ToDo 수정해야 함\n",
    "                key = cv2.waitKey(1) & 0xff\n",
    "                if key in range(48, 58):  # 0~9 숫자 입력   ---⑥\n",
    "                    IDX = key - 48  # 선택한 숫자로 트랙커 인덱스 수정\n",
    "                    print('led num ', IDX)\n",
    "                    bboxes.append({'idx': IDX, 'bbox': bbox})\n",
    "                    break\n",
    "                elif cv2.waitKey(1) == ord('q'):\n",
    "                    bboxes.clear()\n",
    "                    break\n",
    "\n",
    "        elif cv2.waitKey(1) == ord('n'):\n",
    "            break\n",
    "\n",
    "        elif cv2.waitKey(1) & 0xFF == 27:  # Esc pressed\n",
    "            cap.release()\n",
    "            cv2.destroyAllWindows()\n",
    "            break\n",
    "\n",
    "        if len(bboxes) > 0:\n",
    "            for i, data in enumerate(bboxes):\n",
    "                (x, y, w, h) = data['bbox']\n",
    "                IDX = data['idx']\n",
    "                cv2.rectangle(img_draw, (int(x), int(y)), (int(x + w), int(y + h)), (0, 255, 0), 2, 1)\n",
    "                view_camera_infos(img_draw, ''.join([f'{IDX}']), int(x), int(y) - 10)\n",
    "                view_camera_infos(img_draw, ''.join(['[', f'{IDX}', '] '\n",
    "                                                        , f' {x}'\n",
    "                                                        , f' {y}']), 30, 35 + i * 30)\n",
    "\n",
    "        view_camera_infos(img_draw, ''.join(['Cam[', f'{cam_id}', '] ', f'{video_src}']),\n",
    "                            height - 250, 35)\n",
    "\n",
    "        cv2.circle(img_draw, (int(height / 2), int(width / 2)), 3, color=(0, 0, 255),\n",
    "                    thickness=-1)\n",
    "\n",
    "        cv2.imshow('MultiTracker', img_draw)\n",
    "\n",
    "    # end while\n",
    "    print('Selected bounding boxes {}'.format(bboxes))\n",
    "\n",
    "    # Specify the tracker type\n",
    "    trackerType = \"CSRT\"\n",
    "\n",
    "    # Create MultiTracker object\n",
    "    multiTracker = cv2.legacy.MultiTracker_create()\n",
    "\n",
    "    tracker_start = 0\n",
    "    recording_start = 0\n",
    "\n",
    "    # Process video and track objects\n",
    "    while cap.isOpened():\n",
    "        success, frame = cap.read()\n",
    "        if not success:\n",
    "            break\n",
    "\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        frame = Rotate(frame, 270)\n",
    "        img_gray = frame.copy()\n",
    "\n",
    "        # Initialize MultiTracker\n",
    "        if tracker_start == 0:\n",
    "            for i, data in enumerate(bboxes):\n",
    "                multiTracker.add(createTrackerByName(trackerType), img_gray, data['bbox'])\n",
    "\n",
    "        tracker_start = 1\n",
    "\n",
    "        # get updated location of objects in subsequent frames\n",
    "        qq, boxes = multiTracker.update(img_gray)\n",
    "\n",
    "        # draw tracked objects\n",
    "        for i, newbox in enumerate(boxes):\n",
    "            p1 = (int(newbox[0]), int(newbox[1]))\n",
    "            p2 = (int(newbox[0] + newbox[2]), int(newbox[1] + newbox[3]))\n",
    "            cv2.rectangle(img_gray, p1, p2, 255, 2, 1)\n",
    "            IDX = bboxes[i]['idx']\n",
    "            view_camera_infos(img_gray, ''.join([f'{IDX}']), int(newbox[0]), int(newbox[1]) - 10)\n",
    "        \n",
    "        # add graysum find center\n",
    "        for i, newbox in enumerate(boxes):\n",
    "            IDX = bboxes[i]['idx']\n",
    "            ret, new_blobs = find_center(img_gray, IDX, int(newbox[0]), int(newbox[1]),\n",
    "                                            int(newbox[2]), int(newbox[3]), blobs)\n",
    "            if ret == DONE:\n",
    "                blobs = new_blobs\n",
    "\n",
    "        KEY = cv2.waitKey(CAM_DELAY)\n",
    "\n",
    "        # ToDo\n",
    "        if ret == DONE:\n",
    "            ret_status, min_blob = simple_solvePNP(cam_id, frame, blobs)\n",
    "            if ret_status == SUCCESS:\n",
    "                leds_dic['cam_info'][cam_id]['blobs'] = min_blob\n",
    "                leds_dic['cam_info'][cam_id]['med_blobs'].append(min_blob)\n",
    "\n",
    "                cv2.rectangle(img_gray, (10, 10), (height - 10, width - 10), 255, 2)\n",
    "                cam_ori = R.from_rotvec(leds_dic['cam_info'][cam_id]['RER']['C_R_T']['rvecs'].reshape(3)).as_quat()\n",
    "                cam_ori_euler = np.round_(get_euler_from_quat('xyz', cam_ori), 3)\n",
    "                cam_ori_quat = np.round_(get_quat_from_euler('xyz', cam_ori_euler), 8)\n",
    "                cam_pos = leds_dic['cam_info'][cam_id]['RER']['C_R_T']['tvecs'].reshape(3)\n",
    "                cv2.putText(img_gray, ''.join(['rot 'f'{cam_ori_euler}']),\n",
    "                            (20, 35),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.6, 255, lineType=cv2.LINE_AA)\n",
    "                cv2.putText(img_gray, ''.join(['quat 'f'{cam_ori_quat}']),\n",
    "                            (20, 65),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.6, 255, lineType=cv2.LINE_AA)\n",
    "                cv2.putText(img_gray, ''.join(['pos 'f'{cam_pos}']),\n",
    "                            (20, 95),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.6, 255, lineType=cv2.LINE_AA)\n",
    "            stacked = len(leds_dic['cam_info'][cam_id]['med_blobs'])\n",
    "            cv2.putText(img_gray, ''.join([f'{stacked}', ' data stacked']),\n",
    "                        (20, 125),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, 255, lineType=cv2.LINE_AA)\n",
    "\n",
    "\n",
    "             # quit on ESC button\n",
    "            if KEY & 0xFF == 27:  # Esc pressed\n",
    "                cap.release()\n",
    "                cv2.destroyAllWindows()\n",
    "                break\n",
    "            elif KEY == ord('e'):\n",
    "                break\n",
    "            elif KEY == ord('s'):\n",
    "                if recording_start == 0:\n",
    "                    # w = round(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "                    # h = round(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "                    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "                    # print('w', w, 'h', h, 'fps', fps)\n",
    "                    # fourcc  val 받아오기, *는 문자를 풀어쓰는 방식, *'DIVX' == 'D', 'I', 'V', 'X'\n",
    "                    delay = round(1000 / fps)\n",
    "                    now = datetime.datetime.now()\n",
    "                    recording_file_name = ''.join([f'{now}', '.avi'])\n",
    "                    print('recording start', ' ', recording_file_name)\n",
    "                    fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "                    recording_out = cv2.VideoWriter(recording_file_name, fourcc, fps,\n",
    "                                                    (CAP_PROP_FRAME_WIDTH, CAP_PROP_FRAME_HEIGHT))\n",
    "                    recording_start = 1\n",
    "\n",
    "                    leds_dic['cam_info'][cam_id]['track_cal']['recording'] = {'name': recording_file_name}\n",
    "\n",
    "            elif KEY == ord('c'):\n",
    "                blob_array, rt_array = median_blobs(cam_id,\n",
    "                                                    leds_dic['cam_info'][cam_id]['med_blobs'],\n",
    "                                                    leds_dic['cam_info'][cam_id]['D_R_T_A'])\n",
    "\n",
    "                leds_dic['cam_info'][cam_id]['track_cal']['data'] = {'idx': cam_id, 'blobs': blob_array,\n",
    "                                                                     'R_T': rt_array}\n",
    "\n",
    "                leds_dic['cam_info'][cam_id]['med_blobs'].clear()\n",
    "                leds_dic['cam_info'][cam_id]['D_R_T_A'].clear()\n",
    "\n",
    "                print(leds_dic['cam_info'][cam_id]['track_cal'])\n",
    "\n",
    "                if recording_start == 1:\n",
    "                    recording_out.release()\n",
    "                    recording_start = 0\n",
    "                break\n",
    "\n",
    "            # print current stacked data\n",
    "            for i, track_data in enumerate(leds_dic['cam_info'][cam_id]['track_cal']['data']):\n",
    "                track_r = R.from_rotvec(track_data['R_T']['rvecs'].reshape(3)).as_quat()\n",
    "                track_r_euler = np.round_(get_euler_from_quat('xyz', track_r), 3)\n",
    "                track_t = track_data['R_T']['tvecs'].reshape(3)\n",
    "                cv2.putText(img_gray, ''.join(['R 'f'{track_r_euler}',\n",
    "                                               ' T 'f'{track_t}']),\n",
    "                            (CAP_PROP_FRAME_WIDTH - 400, 35 + i * 20),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.3, 255, lineType=cv2.LINE_AA)\n",
    "\n",
    "            if recording_start == 1:\n",
    "                recording_out.write(frame)\n",
    "\n",
    "            # show frame\n",
    "            cv2.imshow('MultiTracker', img_gray)\n",
    "\n",
    "            # release camera frame\n",
    "        if recording_start == 1:\n",
    "            recording_out.release()\n",
    "\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "        bboxes.clear()\n",
    "        blobs.clear()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
